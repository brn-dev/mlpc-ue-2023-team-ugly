{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### from typing import Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.decomposition\n",
    "\n",
    "from lib.data_preprocessing import remove_correlated_columns, normalize_data\n",
    "from lib.ds.bird_classes import NUM_CLASSES\n",
    "from lib.ds.dataset_loading import load_all_data, flatten\n",
    "from lib.ds.dataset_splitting import split\n",
    "from lib.ds.torch_dataset import create_data_loader\n",
    "from lib.ds.challenge_dataset import load_challenge_data\n",
    "from lib.model.attention_classifier import AttentionClassifier, AttentionClassifierHyperParameters\n",
    "from lib.model.sliding_attention_classifier import SlidingAttentionClassifier, SlidingAttentionClassifierHyperParameters\n",
    "from lib.torch_generic_model_training import train_model_with_cv\n",
    "from lib.training_hyper_parameters import TrainingHyperParameters\n",
    "from lib.ds.numpy_dataset import NumpyDataset\n",
    "from lib.model.model_persistence import save_model, load_model\n",
    "from lib.random import set_random_seed\n",
    "from lib.metrics import calculate_average_metrics_for_final_epoch_of_folds, calculate_average_metrics_per_epoch, calculate_average_metrics\n",
    "from lib.ds.bird_combiner import combine_birds\n",
    "from lib.challenge import predict_for_challenge, save_results_to_csv, load_results_from_csv\n",
    "from lib.label_fixing import fix_labels_information_gain\n",
    "import lib.torch_device as tdev\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tdev.PREFERRED = 'cpu'\n",
    "device = tdev.get_torch_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_raw.shape = (1200, 100, 548)\n",
      "labels.shape   = (1200, 100)\n"
     ]
    }
   ],
   "source": [
    "data_raw, labels = load_all_data('dataset')\n",
    "print(f'{data_raw.shape = }')\n",
    "print(f'{labels.shape   = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_raw_train.data.shape = (960, 100, 548)\n",
      "dataset_raw_test.data.shape  = (240, 100, 548)\n"
     ]
    }
   ],
   "source": [
    "dataset_raw_train, dataset_raw_test = split(NumpyDataset(data_raw, labels), test_size_pct=0.2, seed=69420666)\n",
    "\n",
    "\n",
    "print(f'{dataset_raw_train.data.shape = }')\n",
    "print(f'{dataset_raw_test.data.shape  = }' if dataset_raw_test is not None else 'dataset_raw_test             = None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating random sequence (num_duplicates = 1): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 96000/96000 [01:19<00:00, 1200.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences_ds_train.data.shape   = (320, 300, 548)\n",
      "sequences_ds_train.labels.shape = (320, 300)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating random sequence (num_duplicates = 1): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24000/24000 [00:05<00:00, 4612.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences_ds_test.data.shape   = (80, 300, 548)\n",
      "sequences_ds_test.labels.shape = (80, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sequences_ds_train = combine_birds(\n",
    "    dataset_raw_train, \n",
    "    sequence_length=300,\n",
    "    random_seed=42\n",
    ")\n",
    "print(f'{sequences_ds_train.data.shape   = }')\n",
    "print(f'{sequences_ds_train.labels.shape = }\\n\\n')\n",
    "\n",
    "\n",
    "sequences_ds_test = combine_birds(\n",
    "    dataset_raw_test, \n",
    "    sequence_length=300,\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "if sequences_ds_test is not None:\n",
    "    print(f'{sequences_ds_test.data.shape   = }')\n",
    "    print(f'{sequences_ds_test.labels.shape = }')\n",
    "else:\n",
    "    print('sequences_ds_test = None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_hyper_parameters = SlidingAttentionClassifierHyperParameters(\n",
    "    in_features=data_raw.shape[-1],\n",
    "    out_features=NUM_CLASSES,\n",
    "    \n",
    "    attention_window_size=30,\n",
    "    stride=10,\n",
    "    \n",
    "    d_model=64,\n",
    "    num_heads=16,\n",
    "    attention_stack_size=0,\n",
    "    attention_stack_activation_provider=lambda: nn.LeakyReLU(),\n",
    "    attention_dropout=0.45,\n",
    "    \n",
    "    in_linear_hidden_out_features=[128, 64, 64],\n",
    "    out_linear_hidden_out_features=[32, 16],\n",
    "    linear_activation_provider=lambda: nn.LeakyReLU(),\n",
    "    linear_dropout=0.45,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_hyper_parameters = TrainingHyperParameters(\n",
    "        batch_size=17,\n",
    "        \n",
    "        loss_weight_modifiers=torch.Tensor([\n",
    "            1.0 / 3, # 0\n",
    "            1.0, # 1\n",
    "            1.0 / 0.5, # 2\n",
    "            1.0 / 0.5, # 3\n",
    "            1.0, # 4\n",
    "            1.0, # 5\n",
    "            1.0, # 6\n",
    "        ]),\n",
    "        \n",
    "        optimizer_provider=lambda model, lr: optim.Adamax(\n",
    "            model.parameters(),\n",
    "            lr=lr,\n",
    "            betas=(0.9, 0.98),\n",
    "            eps=1e-9\n",
    "        ),\n",
    "\n",
    "        num_epochs=200,\n",
    "        lr=1e-2,\n",
    "    \n",
    "        lr_scheduler_milestones=[int(m) for m in [30, 100, 250]],\n",
    "        lr_scheduler_gamma=0.75,\n",
    "        lr_scheduler_provider=lambda optimizer, milestones, gamma: None,\n",
    "        # lr_scheduler_provider=lambda optimizer, milestones, gamma: lr_scheduler.MultiStepLR(\n",
    "        #     optimizer, \n",
    "        #     milestones=milestones,\n",
    "        #     gamma=gamma\n",
    "        # )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 8 folds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Folds:   0%|                                                                                                                                                                                                                     | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Executing CV for fold 0\n",
      "Training fold 0\n",
      "\n",
      "\n",
      "#### Training ####\n",
      "##################\n",
      "SlidingAttentionClassifier with 89575 parameters, in_fnn: 86848, attention_stack: 0, out_fnn: 2727\n",
      "##################\n",
      "\n",
      "train label counts = [60099,  4234,  5949,  5557,  1577,  3804,  2780]\n",
      "eval label counts  = [ 8493,   513,  1012,   872,   220,   374,   516]\n",
      "\n",
      "loss weights                    = [ 0.33, 14.19, 20.20, 21.63, 38.11, 15.80, 21.62]\n",
      "eval loss weights (theoretical) = [ 0.33, 16.56, 16.78, 19.48, 38.60, 22.71, 16.46]\n",
      "\n",
      "\n",
      "Training Epoch   1/200: lr = 1.00E-02, epoch =     1, avg_loss = 0.000383, num_samples = 84000, num_correct =  5180, acc = 0.061667, bacc = 0.139507, score = -0.380960\n",
      "Evaluation Epoch   1/200: epoch =     1, avg_loss = 0.000610, num_samples = 12000, num_correct =   814, acc = 0.067833, bacc = 0.129434, score = -0.320502\n",
      "Training Epoch   2/200: lr = 1.00E-02, epoch =     2, avg_loss = 0.000373, num_samples = 84000, num_correct =  5435, acc = 0.064702, bacc = 0.137708, score = -0.343545\n",
      "Evaluation Epoch   2/200: epoch =     2, avg_loss = 0.000693, num_samples = 12000, num_correct =  1012, acc = 0.084333, bacc = 0.142857, score = -0.365012\n",
      "Training Epoch   3/200: lr = 1.00E-02, epoch =     3, avg_loss = 0.000371, num_samples = 84000, num_correct =  5877, acc = 0.069964, bacc = 0.143180, score = -0.402037\n",
      "Evaluation Epoch   3/200: epoch =     3, avg_loss = 0.000719, num_samples = 12000, num_correct =   822, acc = 0.068500, bacc = 0.133170, score = -0.304478\n",
      "Training Epoch   4/200: lr = 1.00E-02, epoch =     4, avg_loss = 0.000372, num_samples = 84000, num_correct =  5845, acc = 0.069583, bacc = 0.146455, score = -0.343961\n",
      "Evaluation Epoch   4/200: epoch =     4, avg_loss = 0.000658, num_samples = 12000, num_correct =  1021, acc = 0.085083, bacc = 0.145782, score = -0.352625\n",
      "Training Epoch   5/200: lr = 1.00E-02, epoch =     5, avg_loss = 0.000371, num_samples = 84000, num_correct =  6077, acc = 0.072345, bacc = 0.149124, score = -0.377686\n",
      "Evaluation Epoch   5/200: epoch =     5, avg_loss = 0.000710, num_samples = 12000, num_correct =   819, acc = 0.068250, bacc = 0.132588, score = -0.306487\n",
      "Training Epoch   6/200: lr = 1.00E-02, epoch =     6, avg_loss = 0.000372, num_samples = 84000, num_correct =  5756, acc = 0.068524, bacc = 0.144502, score = -0.346135\n",
      "Evaluation Epoch   6/200: epoch =     6, avg_loss = 0.000714, num_samples = 12000, num_correct =   819, acc = 0.068250, bacc = 0.132611, score = -0.306284\n",
      "Training Epoch   7/200: lr = 1.00E-02, epoch =     7, avg_loss = 0.000371, num_samples = 84000, num_correct =  5833, acc = 0.069440, bacc = 0.146722, score = -0.335718\n",
      "Evaluation Epoch   7/200: epoch =     7, avg_loss = 0.000697, num_samples = 12000, num_correct =   967, acc = 0.080583, bacc = 0.144550, score = -0.326937\n",
      "Training Epoch   8/200: lr = 1.00E-02, epoch =     8, avg_loss = 0.000371, num_samples = 84000, num_correct =  5783, acc = 0.068845, bacc = 0.145076, score = -0.345901\n",
      "Evaluation Epoch   8/200: epoch =     8, avg_loss = 0.000656, num_samples = 12000, num_correct =  1017, acc = 0.084750, bacc = 0.144651, score = -0.357611\n",
      "Training Epoch   9/200: lr = 1.00E-02, epoch =     9, avg_loss = 0.000371, num_samples = 84000, num_correct =  5869, acc = 0.069869, bacc = 0.143169, score = -0.396292\n",
      "Evaluation Epoch   9/200: epoch =     9, avg_loss = 0.000709, num_samples = 12000, num_correct =   991, acc = 0.082583, bacc = 0.146284, score = -0.333956\n",
      "Training Epoch  10/200: lr = 1.00E-02, epoch =    10, avg_loss = 0.000372, num_samples = 84000, num_correct =  5918, acc = 0.070452, bacc = 0.145248, score = -0.379622\n",
      "Evaluation Epoch  10/200: epoch =    10, avg_loss = 0.000697, num_samples = 12000, num_correct =   861, acc = 0.071750, bacc = 0.137270, score = -0.305622\n",
      "Training Epoch  11/200: lr = 1.00E-02, epoch =    11, avg_loss = 0.000371, num_samples = 84000, num_correct =  5844, acc = 0.069571, bacc = 0.145806, score = -0.353182\n",
      "Evaluation Epoch  11/200: epoch =    11, avg_loss = 0.000727, num_samples = 12000, num_correct =   940, acc = 0.078333, bacc = 0.139629, score = -0.343088\n",
      "Training Epoch  12/200: lr = 1.00E-02, epoch =    12, avg_loss = 0.000371, num_samples = 84000, num_correct =  6042, acc = 0.071929, bacc = 0.149940, score = -0.357501\n",
      "Evaluation Epoch  12/200: epoch =    12, avg_loss = 0.000691, num_samples = 12000, num_correct =   892, acc = 0.074333, bacc = 0.139901, score = -0.311040\n",
      "Training Epoch  13/200: lr = 1.00E-02, epoch =    13, avg_loss = 0.000371, num_samples = 84000, num_correct =  5985, acc = 0.071250, bacc = 0.150545, score = -0.330492\n",
      "Evaluation Epoch  13/200: epoch =    13, avg_loss = 0.000707, num_samples = 12000, num_correct =   979, acc = 0.081583, bacc = 0.144318, score = -0.338433\n",
      "Training Epoch  14/200: lr = 1.00E-02, epoch =    14, avg_loss = 0.000371, num_samples = 84000, num_correct =  6137, acc = 0.073060, bacc = 0.150814, score = -0.372014\n",
      "Evaluation Epoch  14/200: epoch =    14, avg_loss = 0.000682, num_samples = 12000, num_correct =   922, acc = 0.076833, bacc = 0.142028, score = -0.317551\n",
      "Training Epoch  15/200: lr = 1.00E-02, epoch =    15, avg_loss = 0.000371, num_samples = 84000, num_correct =  6003, acc = 0.071464, bacc = 0.149151, score = -0.355639\n",
      "Evaluation Epoch  15/200: epoch =    15, avg_loss = 0.000708, num_samples = 12000, num_correct =   914, acc = 0.076167, bacc = 0.138406, score = -0.335813\n",
      "Training Epoch  16/200: lr = 1.00E-02, epoch =    16, avg_loss = 0.000371, num_samples = 84000, num_correct =  5942, acc = 0.070738, bacc = 0.148447, score = -0.346336\n",
      "Evaluation Epoch  16/200: epoch =    16, avg_loss = 0.000676, num_samples = 12000, num_correct =   916, acc = 0.076333, bacc = 0.136966, score = -0.344461\n",
      "Training Epoch  17/200: lr = 1.00E-02, epoch =    17, avg_loss = 0.000371, num_samples = 84000, num_correct =  6074, acc = 0.072310, bacc = 0.151230, score = -0.345875\n",
      "Evaluation Epoch  17/200: epoch =    17, avg_loss = 0.000680, num_samples = 12000, num_correct =   914, acc = 0.076167, bacc = 0.136525, score = -0.345580\n",
      "Training Epoch  18/200: lr = 1.00E-02, epoch =    18, avg_loss = 0.000371, num_samples = 84000, num_correct =  5895, acc = 0.070179, bacc = 0.142651, score = -0.410943\n",
      "Evaluation Epoch  18/200: epoch =    18, avg_loss = 0.000701, num_samples = 12000, num_correct =   980, acc = 0.081667, bacc = 0.142465, score = -0.350972\n",
      "Training Epoch  19/200: lr = 1.00E-02, epoch =    19, avg_loss = 0.000371, num_samples = 84000, num_correct =  6080, acc = 0.072381, bacc = 0.150006, score = -0.367387\n",
      "Evaluation Epoch  19/200: epoch =    19, avg_loss = 0.000707, num_samples = 12000, num_correct =   924, acc = 0.077000, bacc = 0.140928, score = -0.326352\n",
      "Training Epoch  20/200: lr = 1.00E-02, epoch =    20, avg_loss = 0.000371, num_samples = 84000, num_correct =  6096, acc = 0.072571, bacc = 0.150344, score = -0.366027\n",
      "Evaluation Epoch  20/200: epoch =    20, avg_loss = 0.000704, num_samples = 12000, num_correct =   921, acc = 0.076750, bacc = 0.140414, score = -0.328310\n",
      "Training Epoch  21/200: lr = 1.00E-02, epoch =    21, avg_loss = 0.000371, num_samples = 84000, num_correct =  6056, acc = 0.072095, bacc = 0.151472, score = -0.339155\n",
      "Evaluation Epoch  21/200: epoch =    21, avg_loss = 0.000705, num_samples = 12000, num_correct =   914, acc = 0.076167, bacc = 0.142145, score = -0.311294\n",
      "Training Epoch  22/200: lr = 1.00E-02, epoch =    22, avg_loss = 0.000370, num_samples = 84000, num_correct =  6064, acc = 0.072190, bacc = 0.150238, score = -0.356936\n",
      "Evaluation Epoch  22/200: epoch =    22, avg_loss = 0.000706, num_samples = 12000, num_correct =   902, acc = 0.075167, bacc = 0.133312, score = -0.358653\n",
      "Training Epoch  23/200: lr = 1.00E-02, epoch =    23, avg_loss = 0.000371, num_samples = 84000, num_correct =  6037, acc = 0.071869, bacc = 0.149012, score = -0.367212\n",
      "Evaluation Epoch  23/200: epoch =    23, avg_loss = 0.000670, num_samples = 12000, num_correct =   921, acc = 0.076750, bacc = 0.140459, score = -0.328005\n",
      "Training Epoch  24/200: lr = 1.00E-02, epoch =    24, avg_loss = 0.000371, num_samples = 84000, num_correct =  6015, acc = 0.071607, bacc = 0.150908, score = -0.334781\n",
      "Evaluation Epoch  24/200: epoch =    24, avg_loss = 0.000709, num_samples = 12000, num_correct =   890, acc = 0.074167, bacc = 0.139098, score = -0.315364\n",
      "Training Epoch  25/200: lr = 1.00E-02, epoch =    25, avg_loss = 0.000370, num_samples = 84000, num_correct =  6136, acc = 0.073048, bacc = 0.151425, score = -0.362875\n",
      "Evaluation Epoch  25/200: epoch =    25, avg_loss = 0.000700, num_samples = 12000, num_correct =   912, acc = 0.076000, bacc = 0.137013, score = -0.341816\n",
      "Training Epoch  26/200: lr = 1.00E-02, epoch =    26, avg_loss = 0.000371, num_samples = 84000, num_correct =  6081, acc = 0.072393, bacc = 0.149466, score = -0.374133\n",
      "Evaluation Epoch  26/200: epoch =    26, avg_loss = 0.000698, num_samples = 12000, num_correct =   920, acc = 0.076667, bacc = 0.140273, score = -0.328641\n",
      "Training Epoch  27/200: lr = 1.00E-02, epoch =    27, avg_loss = 0.000372, num_samples = 84000, num_correct =  5873, acc = 0.069917, bacc = 0.147862, score = -0.334283\n",
      "Evaluation Epoch  27/200: epoch =    27, avg_loss = 0.000702, num_samples = 12000, num_correct =   929, acc = 0.077417, bacc = 0.143538, score = -0.311625\n",
      "Training Epoch  28/200: lr = 1.00E-02, epoch =    28, avg_loss = 0.000371, num_samples = 84000, num_correct =  6144, acc = 0.073143, bacc = 0.152789, score = -0.346834\n",
      "Evaluation Epoch  28/200: epoch =    28, avg_loss = 0.000695, num_samples = 12000, num_correct =   930, acc = 0.077500, bacc = 0.141118, score = -0.329505\n",
      "Training Epoch  29/200: lr = 1.00E-02, epoch =    29, avg_loss = 0.000371, num_samples = 84000, num_correct =  6168, acc = 0.073429, bacc = 0.153161, score = -0.348625\n",
      "Evaluation Epoch  29/200: epoch =    29, avg_loss = 0.000703, num_samples = 12000, num_correct =   924, acc = 0.077000, bacc = 0.140996, score = -0.326911\n",
      "Training Epoch  30/200: lr = 1.00E-02, epoch =    30, avg_loss = 0.000370, num_samples = 84000, num_correct =  6159, acc = 0.073321, bacc = 0.152934, score = -0.349023\n",
      "Evaluation Epoch  30/200: epoch =    30, avg_loss = 0.000695, num_samples = 12000, num_correct =   921, acc = 0.076750, bacc = 0.140414, score = -0.328310\n",
      "Training Epoch  31/200: lr = 1.00E-02, epoch =    31, avg_loss = 0.000371, num_samples = 84000, num_correct =  6107, acc = 0.072702, bacc = 0.151406, score = -0.354167\n",
      "Evaluation Epoch  31/200: epoch =    31, avg_loss = 0.000696, num_samples = 12000, num_correct =   923, acc = 0.076917, bacc = 0.140719, score = -0.327700\n",
      "Training Epoch  32/200: lr = 1.00E-02, epoch =    32, avg_loss = 0.000371, num_samples = 84000, num_correct =  5905, acc = 0.070298, bacc = 0.147238, score = -0.351387\n",
      "Evaluation Epoch  32/200: epoch =    32, avg_loss = 0.000689, num_samples = 12000, num_correct =   933, acc = 0.077750, bacc = 0.143921, score = -0.311574\n",
      "Training Epoch  33/200: lr = 1.00E-02, epoch =    33, avg_loss = 0.000371, num_samples = 84000, num_correct =  6055, acc = 0.072083, bacc = 0.149892, score = -0.362173\n",
      "Evaluation Epoch  33/200: epoch =    33, avg_loss = 0.000694, num_samples = 12000, num_correct =   926, acc = 0.077167, bacc = 0.136836, score = -0.351125\n",
      "Training Epoch  34/200: lr = 1.00E-02, epoch =    34, avg_loss = 0.000371, num_samples = 84000, num_correct =  6158, acc = 0.073310, bacc = 0.152563, score = -0.354252\n",
      "Evaluation Epoch  34/200: epoch =    34, avg_loss = 0.000700, num_samples = 12000, num_correct =   921, acc = 0.076750, bacc = 0.140414, score = -0.328310\n",
      "Training Epoch  35/200: lr = 1.00E-02, epoch =    35, avg_loss = 0.000370, num_samples = 84000, num_correct =  6143, acc = 0.073131, bacc = 0.151813, score = -0.359556\n",
      "Evaluation Epoch  35/200: epoch =    35, avg_loss = 0.000698, num_samples = 12000, num_correct =   915, acc = 0.076250, bacc = 0.137142, score = -0.342503\n",
      "Training Epoch  36/200: lr = 1.00E-02, epoch =    36, avg_loss = 0.000371, num_samples = 84000, num_correct =  6174, acc = 0.073500, bacc = 0.153207, score = -0.350075\n",
      "Evaluation Epoch  36/200: epoch =    36, avg_loss = 0.000705, num_samples = 12000, num_correct =   919, acc = 0.076583, bacc = 0.139792, score = -0.330345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Folds:   0%|                                                                                                                                                                                                                     | 0/8 [00:07<?, ?it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "set_random_seed(43)\n",
    "\n",
    "cv_models_with_scalers, cv_folds_metrics, best_models_metrics = train_model_with_cv(\n",
    "    lambda: SlidingAttentionClassifier(ac_hyper_parameters, batch_first=True),\n",
    "    training_hyper_parameters, \n",
    "    sequences_ds_train,\n",
    "    sequences_ds_test,\n",
    "    n_folds=8,\n",
    "    device=device,\n",
    "    save_models='best',\n",
    "    model_saving_name='species_classifier',\n",
    ")\n",
    "\n",
    "\n",
    "## Metrics ##\n",
    "print(\n",
    "'''\n",
    "\n",
    "#################\n",
    "#### Metrics ####\n",
    "#################\n",
    "\n",
    "'''\n",
    ")\n",
    "\n",
    "cv_average_best_best_models_eval_metrics = calculate_average_metrics([m[1] for m in best_models_metrics])\n",
    "print(f'{cv_average_best_best_models_eval_metrics = } \\n\\n')\n",
    "\n",
    "if best_models_metrics[0][2] is not None:\n",
    "    cv_average_best_best_models_test_metrics = calculate_average_metrics([m[2] for m in best_models_metrics])\n",
    "    print(f'{cv_average_best_best_models_test_metrics = } \\n\\n')\n",
    "\n",
    "cv_avg_epoch_train_metrics = calculate_average_metrics_per_epoch(cv_folds_metrics)\n",
    "\n",
    "rows = []\n",
    "for fold_nr, fold_metrics in enumerate(cv_folds_metrics):\n",
    "    for epoch_nr, (train_metrics, eval_metrics) in enumerate(fold_metrics):\n",
    "        rows.append({\n",
    "            'cv_fold': fold_nr,\n",
    "            'epoch': epoch_nr,\n",
    "            'type': 'CV Train BACC',\n",
    "            'bacc': train_metrics.bacc,\n",
    "        })\n",
    "        if eval_metrics is not None:\n",
    "            rows.append({\n",
    "                'cv_fold': fold_nr,\n",
    "                'epoch': epoch_nr,\n",
    "                'type': 'CV Eval BACC',\n",
    "                'bacc': eval_metrics.bacc,\n",
    "            })\n",
    "\n",
    "cv_metrics_df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lrs_over_epochs(training_hyper_parameters: TrainingHyperParameters) -> list[float]:\n",
    "    lrs: list[float] = []\n",
    "    \n",
    "    lr = training_hyper_parameters.lr\n",
    "    for epoch_nr in range(training_hyper_parameters.num_epochs):\n",
    "        if epoch_nr in training_hyper_parameters.lr_scheduler_milestones:\n",
    "            lr *= training_hyper_parameters.lr_scheduler_gamma\n",
    "        lrs.append(lr)\n",
    "    return lrs\n",
    "    \n",
    "\n",
    "def plot_baccs_over_epochs(title: str):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 8), dpi=300)\n",
    "    \n",
    "    cv_epoch_range = np.arange(0, training_hyper_parameters.num_epochs)\n",
    "    \n",
    "    sns.lineplot(data=cv_metrics_df, x='epoch', y='bacc', hue='type', ax=ax, palette=['blue', 'green'])\n",
    "    \n",
    "    twin_ax = ax.twinx()\n",
    "    lr_plots_kwargs = {\n",
    "        'ls': '--',\n",
    "        'lw': 0.75\n",
    "    }\n",
    "    twin_ax.plot(cv_epoch_range, create_lrs_over_epochs(training_hyper_parameters), label='CV LR', c='lightblue', **lr_plots_kwargs)\n",
    "\n",
    "    ax.set(\n",
    "        title=title,\n",
    "        xlabel='Epoch',\n",
    "        ylabel='BACC',\n",
    "        yticks=[x * 0.1 for x in range(11)]\n",
    "    )\n",
    "\n",
    "    ax.grid(ls=':')\n",
    "    ax.legend(loc='center right')\n",
    "    twin_ax.legend(loc='lower right')\n",
    "\n",
    "    for spine in ['top', 'right', 'bottom', 'left']:\n",
    "        ax.spines[spine].set_visible(False)\n",
    "        twin_ax.spines[spine].set_visible(False)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "average_last_epoch_eval_bacc = cv_metrics_df.query('type == \"CV Eval BACC\"').groupby('epoch').mean().iloc[-1]['bacc']\n",
    "plot_baccs_over_epochs(f'Attention Classifier, last epoch eval bacc = {average_last_epoch_eval_bacc:6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
