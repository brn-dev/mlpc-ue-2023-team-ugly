{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dab53e0-78e4-477d-866c-4ba5b4df1271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import lib.torch_device as tdev\n",
    "\n",
    "from lib.ds.torch_dataset import create_data_loader\n",
    "from lib.model.attention_classifier import AttentionClassifier, AttentionClassifierHyperParameters\n",
    "from lib.torch_generic_model_training import train_model_with_cv, train_model, evaluate_model\n",
    "from lib.training_hyper_parameters import TrainingHyperParameters\n",
    "from lib.ds.numpy_dataset import NumpyDataset\n",
    "from lib.model.model_persistence import save_model, load_model\n",
    "from lib.random import set_random_seed\n",
    "from lib.metrics import calculate_average_metrics_for_final_epoch_of_folds, calculate_average_metrics_per_epoch, calculate_average_metrics\n",
    "\n",
    "import lib.torch_device as tdev\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "834e44e9-fd01-4387-9074-93e2965f1588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = tdev.get_torch_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6ae89f9e-498a-449e-95e4-4f0ed62e1482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape   = (26, 8, 1)\n",
      "labels.shape = (26, 8)\n",
      "[[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] [1 0 0 0 0 0 0 0]\n",
      "[[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] [0 1 0 0 0 0 0 0]\n",
      "[[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] [0 0 1 0 0 0 0 0]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] [0 0 0 1 0 0 0 0]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] [0 0 0 0 1 0 0 0]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]] [0 0 0 0 0 1 0 0]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]] [0 0 0 0 0 0 1 0]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]] [0 0 0 0 0 0 0 1]\n",
      "[[1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] [0 0 0 0 0 0 0 0]\n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] [0 0 0 0 0 0 0 0]\n",
      "[[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] [0 0 0 0 0 0 0 0]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] [0 0 0 0 0 0 0 0]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]] [0 0 0 0 0 0 0 0]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] [0 0 0 0 0 0 0 0]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]] [0 0 0 0 0 0 0 0]\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] [0 0 1 0 0 0 0 0]\n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] [0 0 0 1 0 0 0 0]\n",
      "[[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] [0 0 0 0 1 0 0 0]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]] [0 0 0 0 0 1 0 0]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] [0 0 0 0 0 0 1 0]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] [0 0 0 0 0 0 0 1]\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] [0 0 0 0 0 0 0 0]\n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] [0 0 0 0 0 0 0 0]\n",
      "[[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]] [0 0 0 0 0 0 0 0]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] [0 0 0 0 0 0 0 0]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] [0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng()\n",
    "\n",
    "def create_random_sequences(sequence_length: int, segments: list[list[int]], segment_end_labels: list[int]):\n",
    "\n",
    "def create_sequences_with_segment(sequence_length: int, segment: list[int], segment_end_label: int):\n",
    "    sequences: list[np.ndarray] = []\n",
    "    labels: list[np.ndarray] = []\n",
    "    segment_length = len(segment)\n",
    "    \n",
    "    for i in range(sequence_length - segment_length + 1):\n",
    "        seq = np.zeros(sequence_length)\n",
    "        l = np.zeros(sequence_length).astype(int)\n",
    "        \n",
    "        seq[i:i + segment_length] = np.array(segment)\n",
    "        l[i + segment_length - 1] = segment_end_label\n",
    "            \n",
    "        sequences.append(seq)\n",
    "        labels.append(l)\n",
    "    \n",
    "    return sequences, labels\n",
    "\n",
    "data = np.array([\n",
    "    *(create_sequences_with_segment(8, [1], segment_end_label=0)[0]),\n",
    "    *(create_sequences_with_segment(8, [1, 1], segment_end_label=0)[0]),\n",
    "    *(create_sequences_with_segment(8, [1, 1, 1], segment_end_label=0)[0]),\n",
    "    *(create_sequences_with_segment(8, [1, 1, 1, 1], segment_end_label=0)[0]),\n",
    "])[:, :, np.newaxis]\n",
    "labels = np.array([\n",
    "    *(create_sequences_with_segment(8, [1], segment_end_label=1)[1]),\n",
    "    *(create_sequences_with_segment(8, [1, 1], segment_end_label=0)[1]),\n",
    "    *(create_sequences_with_segment(8, [1, 1, 1], segment_end_label=1)[1]),\n",
    "    *(create_sequences_with_segment(8, [1, 1, 1, 1], segment_end_label=0)[1]),\n",
    "]).astype(int)\n",
    "\n",
    "ds = NumpyDataset(data, labels)\n",
    "\n",
    "print(f'{data.shape   = }')\n",
    "print(f'{labels.shape = }')\n",
    "\n",
    "for i in range(data.shape[0]):\n",
    "    print(data[i], labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8776fc-1062-40e5-a8b7-9b669f81b8b8",
   "metadata": {},
   "source": [
    "# Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6b067bfd-5d10-4610-b6a0-1f6c9ccde7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_hyper_parameters = AttentionClassifierHyperParameters(\n",
    "    in_features=data.shape[-1],\n",
    "    out_features=2,\n",
    "    \n",
    "    attention_window_size=8,\n",
    "    \n",
    "    d_model=64,\n",
    "    num_heads=16,\n",
    "    attention_stack_size=2,\n",
    "    attention_stack_activation_provider=lambda: nn.LeakyReLU(),\n",
    "    attention_dropout=0.45,\n",
    "    \n",
    "    in_linear_hidden_out_features=[128, 64, 64],\n",
    "    out_linear_hidden_out_features=[32, 16],\n",
    "    linear_activation_provider=lambda: nn.LeakyReLU(),\n",
    "    linear_dropout=0.45,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9657642b-051e-4981-b1d5-1d969292ec46",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_hyper_parameters = TrainingHyperParameters(\n",
    "        batch_size=16,\n",
    "        \n",
    "        loss_weight_factors=None,\n",
    "        \n",
    "        optimizer_provider=lambda model, lr: optim.Adamax(\n",
    "            model.parameters(),\n",
    "            lr=lr,\n",
    "            betas=(0.9, 0.98),\n",
    "            eps=1e-9\n",
    "        ),\n",
    "\n",
    "        num_epochs=275,\n",
    "        lr=1e-3,\n",
    "    \n",
    "        lr_scheduler_milestones=[int(m) for m in [30, 100, 250]],\n",
    "        lr_scheduler_gamma=0.75,\n",
    "        lr_scheduler_provider=lambda optimizer, milestones, gamma: None,\n",
    "        # lr_scheduler_provider=lambda optimizer, milestones, gamma: lr_scheduler.MultiStepLR(\n",
    "        #     optimizer, \n",
    "        #     milestones=milestones,\n",
    "        #     gamma=gamma\n",
    "        # )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db23f909-34be-44ff-9df8-31be202fad87",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "215573ce-bc53-4013-af5a-a9a21301c73c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 1, 64])\n",
      "\n",
      "\n",
      "#### Training ####\n",
      "##################\n",
      "AttentionClassifier with 52754 parameters, in_fnn: 16832, attention_stack: 33280, out_fnn: 2642\n",
      "##################\n",
      "\n",
      "train label counts = [  194,    14]\n",
      "eval label counts  = [  194,    14]\n",
      "\n",
      "loss weights                    = [ 1.00, 13.86]\n",
      "eval loss weights (theoretical) = [ 1.00, 13.86]\n",
      "\n",
      "\n",
      "Training Epoch   1/275: lr = 1.00E-03, epoch =     1, avg_loss = 0.006668, num_samples =   208, num_correct =   164, acc = 0.788462, bacc = 0.455817, score = 0.576923\n",
      "Evaluation Epoch   1/275: epoch =     1, avg_loss = 0.006431, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385\n",
      "Training Epoch   2/275: lr = 1.00E-03, epoch =     2, avg_loss = 0.006673, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385\n",
      "Evaluation Epoch   2/275: epoch =     2, avg_loss = 0.006463, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385\n",
      "Training Epoch   3/275: lr = 1.00E-03, epoch =     3, avg_loss = 0.006662, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385\n",
      "Evaluation Epoch   3/275: epoch =     3, avg_loss = 0.006507, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385\n",
      "Training Epoch   4/275: lr = 1.00E-03, epoch =     4, avg_loss = 0.006665, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385\n",
      "Evaluation Epoch   4/275: epoch =     4, avg_loss = 0.006528, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385\n",
      "Training Epoch   5/275: lr = 1.00E-03, epoch =     5, avg_loss = 0.006665, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385\n",
      "Evaluation Epoch   5/275: epoch =     5, avg_loss = 0.006548, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385\n",
      "Training Epoch   6/275: lr = 1.00E-03, epoch =     6, avg_loss = 0.006668, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385\n",
      "Evaluation Epoch   6/275: epoch =     6, avg_loss = 0.006556, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385\n",
      "Training Epoch   7/275: lr = 1.00E-03, epoch =     7, avg_loss = 0.006666, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385\n",
      "Evaluation Epoch   7/275: epoch =     7, avg_loss = 0.006581, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385\n",
      "Training Epoch   8/275: lr = 1.00E-03, epoch =     8, avg_loss = 0.006665, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385\n",
      "Evaluation Epoch   8/275: epoch =     8, avg_loss = 0.006612, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385\n",
      "Training Epoch   9/275: lr = 1.00E-03, epoch =     9, avg_loss = 0.006664, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385\n",
      "Evaluation Epoch   9/275: epoch =     9, avg_loss = 0.006636, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385\n",
      "Training Epoch  10/275: lr = 1.00E-03, epoch =    10, avg_loss = 0.006665, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385\n",
      "Evaluation Epoch  10/275: epoch =    10, avg_loss = 0.006638, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385\n",
      "Training Epoch  11/275: lr = 1.00E-03, epoch =    11, avg_loss = 0.006666, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385\n",
      "Evaluation Epoch  11/275: epoch =    11, avg_loss = 0.006639, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385\n",
      "Training Epoch  12/275: lr = 1.00E-03, epoch =    12, avg_loss = 0.006665, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385\n",
      "Evaluation Epoch  12/275: epoch =    12, avg_loss = 0.006654, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385\n",
      "Training Epoch  13/275: lr = 1.00E-03, epoch =    13, avg_loss = 0.006664, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385\n",
      "Evaluation Epoch  13/275: epoch =    13, avg_loss = 0.006671, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385\n",
      "Training Epoch  14/275: lr = 1.00E-03, epoch =    14, avg_loss = 0.006665, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385\n",
      "Evaluation Epoch  14/275: epoch =    14, avg_loss = 0.006691, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385\n",
      "Training Epoch  15/275: lr = 1.00E-03, epoch =    15, avg_loss = 0.006665, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385\n",
      "Evaluation Epoch  15/275: epoch =    15, avg_loss = 0.006692, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385\n",
      "Training Epoch  16/275: lr = 1.00E-03, epoch =    16, avg_loss = 0.006665, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385\n",
      "Evaluation Epoch  16/275: epoch =    16, avg_loss = 0.006706, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385\n",
      "Training Epoch  17/275: lr = 1.00E-03, epoch =    17, avg_loss = 0.006664, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385\n",
      "Evaluation Epoch  17/275: epoch =    17, avg_loss = 0.006710, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385\n",
      "Training Epoch  18/275: lr = 1.00E-03, epoch =    18, avg_loss = 0.006665, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385\n",
      "Evaluation Epoch  18/275: epoch =    18, avg_loss = 0.006718, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385\n",
      "Training Epoch  19/275: lr = 1.00E-03, epoch =    19, avg_loss = 0.006664, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385\n",
      "Evaluation Epoch  19/275: epoch =    19, avg_loss = 0.006713, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385\n",
      "Training Epoch  20/275: lr = 1.00E-03, epoch =    20, avg_loss = 0.006664, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385\n",
      "Evaluation Epoch  20/275: epoch =    20, avg_loss = 0.006715, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385\n",
      "Training Epoch  21/275: lr = 1.00E-03, epoch =    21, avg_loss = 0.006664, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385\n",
      "Evaluation Epoch  21/275: epoch =    21, avg_loss = 0.006705, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385\n",
      "Training Epoch  22/275: lr = 1.00E-03, epoch =    22, avg_loss = 0.006663, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385\n",
      "Evaluation Epoch  22/275: epoch =    22, avg_loss = 0.006699, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385\n",
      "Training Epoch  23/275: lr = 1.00E-03, epoch =    23, avg_loss = 0.006664, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385\n",
      "Evaluation Epoch  23/275: epoch =    23, avg_loss = 0.006698, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385\n",
      "Training Epoch  24/275: lr = 1.00E-03, epoch =    24, avg_loss = 0.006663, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385\n",
      "Evaluation Epoch  24/275: epoch =    24, avg_loss = 0.006701, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385\n",
      "Training Epoch  25/275: lr = 1.00E-03, epoch =    25, avg_loss = 0.006663, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385\n",
      "Evaluation Epoch  25/275: epoch =    25, avg_loss = 0.006710, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385\n",
      "Training Epoch  26/275: lr = 1.00E-03, epoch =    26, avg_loss = 0.006663, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385\n",
      "Evaluation Epoch  26/275: epoch =    26, avg_loss = 0.006697, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385\n",
      "Training Epoch  27/275: lr = 1.00E-03, epoch =    27, avg_loss = 0.006663, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385\n",
      "Evaluation Epoch  27/275: epoch =    27, avg_loss = 0.006694, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385\n",
      "Training Epoch  28/275: lr = 1.00E-03, epoch =    28, avg_loss = 0.006661, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385\n",
      "Evaluation Epoch  28/275: epoch =    28, avg_loss = 0.006706, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385\n",
      "Training Epoch  29/275: lr = 1.00E-03, epoch =    29, avg_loss = 0.006661, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385\n",
      "Evaluation Epoch  29/275: epoch =    29, avg_loss = 0.006720, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385\n",
      "Training Epoch  30/275: lr = 1.00E-03, epoch =    30, avg_loss = 0.006661, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385\n",
      "Evaluation Epoch  30/275: epoch =    30, avg_loss = 0.006724, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385\n",
      "Training Epoch  31/275: lr = 1.00E-03, epoch =    31, avg_loss = 0.006660, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385\n",
      "Evaluation Epoch  31/275: epoch =    31, avg_loss = 0.006742, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385\n",
      "Training Epoch  32/275: lr = 1.00E-03, epoch =    32, avg_loss = 0.006665, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385\n",
      "Evaluation Epoch  32/275: epoch =    32, avg_loss = 0.006763, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385\n",
      "Training Epoch  33/275: lr = 1.00E-03, epoch =    33, avg_loss = 0.006660, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385\n",
      "Evaluation Epoch  33/275: epoch =    33, avg_loss = 0.006749, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385\n",
      "Training Epoch  34/275: lr = 1.00E-03, epoch =    34, avg_loss = 0.006659, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385\n",
      "Evaluation Epoch  34/275: epoch =    34, avg_loss = 0.006724, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385\n",
      "Training Epoch  35/275: lr = 1.00E-03, epoch =    35, avg_loss = 0.006657, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385\n",
      "Evaluation Epoch  35/275: epoch =    35, avg_loss = 0.006703, num_samples =   208, num_correct =    38, acc = 0.182692, bacc = 0.561856, score = -0.634615\n",
      "Training Epoch  36/275: lr = 1.00E-03, epoch =    36, avg_loss = 0.006656, num_samples =   208, num_correct =    46, acc = 0.221154, bacc = 0.582474, score = -0.557692\n",
      "Evaluation Epoch  36/275: epoch =    36, avg_loss = 0.006688, num_samples =   208, num_correct =    54, acc = 0.259615, bacc = 0.603093, score = -0.480769\n",
      "Training Epoch  37/275: lr = 1.00E-03, epoch =    37, avg_loss = 0.006657, num_samples =   208, num_correct =    66, acc = 0.317308, bacc = 0.567747, score = -0.365385\n",
      "Evaluation Epoch  37/275: epoch =    37, avg_loss = 0.006669, num_samples =   208, num_correct =    90, acc = 0.432692, bacc = 0.497054, score = -0.134615\n",
      "Training Epoch  38/275: lr = 1.00E-03, epoch =    38, avg_loss = 0.006657, num_samples =   208, num_correct =    84, acc = 0.403846, bacc = 0.514728, score = -0.192308\n",
      "Evaluation Epoch  38/275: epoch =    38, avg_loss = 0.006679, num_samples =   208, num_correct =    84, acc = 0.403846, bacc = 0.514728, score = -0.192308\n",
      "Training Epoch  39/275: lr = 1.00E-03, epoch =    39, avg_loss = 0.006658, num_samples =   208, num_correct =    90, acc = 0.432692, bacc = 0.497054, score = -0.134615\n",
      "Evaluation Epoch  39/275: epoch =    39, avg_loss = 0.006640, num_samples =   208, num_correct =   106, acc = 0.509615, bacc = 0.538292, score = 0.019231\n",
      "Training Epoch  40/275: lr = 1.00E-03, epoch =    40, avg_loss = 0.006652, num_samples =   208, num_correct =   122, acc = 0.586538, bacc = 0.579529, score = 0.173077\n",
      "Evaluation Epoch  40/275: epoch =    40, avg_loss = 0.006635, num_samples =   208, num_correct =   122, acc = 0.586538, bacc = 0.579529, score = 0.173077\n",
      "Training Epoch  41/275: lr = 1.00E-03, epoch =    41, avg_loss = 0.006655, num_samples =   208, num_correct =    98, acc = 0.471154, bacc = 0.517673, score = -0.057692\n",
      "Evaluation Epoch  41/275: epoch =    41, avg_loss = 0.006637, num_samples =   208, num_correct =    90, acc = 0.432692, bacc = 0.497054, score = -0.134615\n",
      "Training Epoch  42/275: lr = 1.00E-03, epoch =    42, avg_loss = 0.006646, num_samples =   208, num_correct =    98, acc = 0.471154, bacc = 0.517673, score = -0.057692\n",
      "Evaluation Epoch  42/275: epoch =    42, avg_loss = 0.006610, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch  43/275: lr = 1.00E-03, epoch =    43, avg_loss = 0.006645, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch  43/275: epoch =    43, avg_loss = 0.006596, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch  44/275: lr = 1.00E-03, epoch =    44, avg_loss = 0.006644, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch  44/275: epoch =    44, avg_loss = 0.006573, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch  45/275: lr = 1.00E-03, epoch =    45, avg_loss = 0.006642, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch  45/275: epoch =    45, avg_loss = 0.006571, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch  46/275: lr = 1.00E-03, epoch =    46, avg_loss = 0.006636, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch  46/275: epoch =    46, avg_loss = 0.006557, num_samples =   208, num_correct =   138, acc = 0.663462, bacc = 0.620766, score = 0.326923\n",
      "Training Epoch  47/275: lr = 1.00E-03, epoch =    47, avg_loss = 0.006620, num_samples =   208, num_correct =   122, acc = 0.586538, bacc = 0.579529, score = 0.173077\n",
      "Evaluation Epoch  47/275: epoch =    47, avg_loss = 0.006579, num_samples =   208, num_correct =   106, acc = 0.509615, bacc = 0.538292, score = 0.019231\n",
      "Training Epoch  48/275: lr = 1.00E-03, epoch =    48, avg_loss = 0.006621, num_samples =   208, num_correct =   106, acc = 0.509615, bacc = 0.538292, score = 0.019231\n",
      "Evaluation Epoch  48/275: epoch =    48, avg_loss = 0.006538, num_samples =   208, num_correct =   138, acc = 0.663462, bacc = 0.620766, score = 0.326923\n",
      "Training Epoch  49/275: lr = 1.00E-03, epoch =    49, avg_loss = 0.006626, num_samples =   208, num_correct =   138, acc = 0.663462, bacc = 0.620766, score = 0.326923\n",
      "Evaluation Epoch  49/275: epoch =    49, avg_loss = 0.006533, num_samples =   208, num_correct =   130, acc = 0.625000, bacc = 0.600147, score = 0.250000\n",
      "Training Epoch  50/275: lr = 1.00E-03, epoch =    50, avg_loss = 0.006611, num_samples =   208, num_correct =   106, acc = 0.509615, bacc = 0.538292, score = 0.019231\n",
      "Evaluation Epoch  50/275: epoch =    50, avg_loss = 0.006541, num_samples =   208, num_correct =   122, acc = 0.586538, bacc = 0.579529, score = 0.173077\n",
      "Training Epoch  51/275: lr = 1.00E-03, epoch =    51, avg_loss = 0.006614, num_samples =   208, num_correct =   122, acc = 0.586538, bacc = 0.579529, score = 0.173077\n",
      "Evaluation Epoch  51/275: epoch =    51, avg_loss = 0.006528, num_samples =   208, num_correct =   122, acc = 0.586538, bacc = 0.579529, score = 0.173077\n",
      "Training Epoch  52/275: lr = 1.00E-03, epoch =    52, avg_loss = 0.006603, num_samples =   208, num_correct =   122, acc = 0.586538, bacc = 0.579529, score = 0.173077\n",
      "Evaluation Epoch  52/275: epoch =    52, avg_loss = 0.006518, num_samples =   208, num_correct =   106, acc = 0.509615, bacc = 0.538292, score = 0.019231\n",
      "Training Epoch  53/275: lr = 1.00E-03, epoch =    53, avg_loss = 0.006600, num_samples =   208, num_correct =   106, acc = 0.509615, bacc = 0.538292, score = 0.019231\n",
      "Evaluation Epoch  53/275: epoch =    53, avg_loss = 0.006513, num_samples =   208, num_correct =   106, acc = 0.509615, bacc = 0.538292, score = 0.019231\n",
      "Training Epoch  54/275: lr = 1.00E-03, epoch =    54, avg_loss = 0.006582, num_samples =   208, num_correct =   114, acc = 0.548077, bacc = 0.558910, score = 0.096154\n",
      "Evaluation Epoch  54/275: epoch =    54, avg_loss = 0.006427, num_samples =   208, num_correct =   138, acc = 0.663462, bacc = 0.620766, score = 0.326923\n",
      "Training Epoch  55/275: lr = 1.00E-03, epoch =    55, avg_loss = 0.006594, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch  55/275: epoch =    55, avg_loss = 0.006354, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch  56/275: lr = 1.00E-03, epoch =    56, avg_loss = 0.006594, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch  56/275: epoch =    56, avg_loss = 0.006331, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch  57/275: lr = 1.00E-03, epoch =    57, avg_loss = 0.006547, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch  57/275: epoch =    57, avg_loss = 0.006429, num_samples =   208, num_correct =   122, acc = 0.586538, bacc = 0.579529, score = 0.173077\n",
      "Training Epoch  58/275: lr = 1.00E-03, epoch =    58, avg_loss = 0.006555, num_samples =   208, num_correct =   122, acc = 0.586538, bacc = 0.579529, score = 0.173077\n",
      "Evaluation Epoch  58/275: epoch =    58, avg_loss = 0.006545, num_samples =   208, num_correct =    90, acc = 0.432692, bacc = 0.497054, score = -0.134615\n",
      "Training Epoch  59/275: lr = 1.00E-03, epoch =    59, avg_loss = 0.006554, num_samples =   208, num_correct =    90, acc = 0.432692, bacc = 0.497054, score = -0.134615\n",
      "Evaluation Epoch  59/275: epoch =    59, avg_loss = 0.006567, num_samples =   208, num_correct =    90, acc = 0.432692, bacc = 0.497054, score = -0.134615\n",
      "Training Epoch  60/275: lr = 1.00E-03, epoch =    60, avg_loss = 0.006547, num_samples =   208, num_correct =    90, acc = 0.432692, bacc = 0.497054, score = -0.134615\n",
      "Evaluation Epoch  60/275: epoch =    60, avg_loss = 0.006392, num_samples =   208, num_correct =   106, acc = 0.509615, bacc = 0.538292, score = 0.019231\n",
      "Training Epoch  61/275: lr = 1.00E-03, epoch =    61, avg_loss = 0.006531, num_samples =   208, num_correct =   114, acc = 0.548077, bacc = 0.558910, score = 0.096154\n",
      "Evaluation Epoch  61/275: epoch =    61, avg_loss = 0.006250, num_samples =   208, num_correct =   138, acc = 0.663462, bacc = 0.620766, score = 0.326923\n",
      "Training Epoch  62/275: lr = 1.00E-03, epoch =    62, avg_loss = 0.006534, num_samples =   208, num_correct =   130, acc = 0.625000, bacc = 0.600147, score = 0.250000\n",
      "Evaluation Epoch  62/275: epoch =    62, avg_loss = 0.006308, num_samples =   208, num_correct =   122, acc = 0.586538, bacc = 0.579529, score = 0.173077\n",
      "Training Epoch  63/275: lr = 1.00E-03, epoch =    63, avg_loss = 0.006520, num_samples =   208, num_correct =   106, acc = 0.509615, bacc = 0.538292, score = 0.019231\n",
      "Evaluation Epoch  63/275: epoch =    63, avg_loss = 0.006387, num_samples =   208, num_correct =    90, acc = 0.432692, bacc = 0.497054, score = -0.134615\n",
      "Training Epoch  64/275: lr = 1.00E-03, epoch =    64, avg_loss = 0.006535, num_samples =   208, num_correct =    90, acc = 0.432692, bacc = 0.497054, score = -0.134615\n",
      "Evaluation Epoch  64/275: epoch =    64, avg_loss = 0.006352, num_samples =   208, num_correct =    98, acc = 0.471154, bacc = 0.517673, score = -0.057692\n",
      "Training Epoch  65/275: lr = 1.00E-03, epoch =    65, avg_loss = 0.006513, num_samples =   208, num_correct =   106, acc = 0.509615, bacc = 0.538292, score = 0.019231\n",
      "Evaluation Epoch  65/275: epoch =    65, avg_loss = 0.006289, num_samples =   208, num_correct =   106, acc = 0.509615, bacc = 0.538292, score = 0.019231\n",
      "Training Epoch  66/275: lr = 1.00E-03, epoch =    66, avg_loss = 0.006509, num_samples =   208, num_correct =   106, acc = 0.509615, bacc = 0.538292, score = 0.019231\n",
      "Evaluation Epoch  66/275: epoch =    66, avg_loss = 0.006316, num_samples =   208, num_correct =    98, acc = 0.471154, bacc = 0.517673, score = -0.057692\n",
      "Training Epoch  67/275: lr = 1.00E-03, epoch =    67, avg_loss = 0.006411, num_samples =   208, num_correct =    98, acc = 0.471154, bacc = 0.517673, score = -0.057692\n",
      "Evaluation Epoch  67/275: epoch =    67, avg_loss = 0.006215, num_samples =   208, num_correct =   114, acc = 0.548077, bacc = 0.558910, score = 0.096154\n",
      "Training Epoch  68/275: lr = 1.00E-03, epoch =    68, avg_loss = 0.006492, num_samples =   208, num_correct =   122, acc = 0.586538, bacc = 0.579529, score = 0.173077\n",
      "Evaluation Epoch  68/275: epoch =    68, avg_loss = 0.006041, num_samples =   208, num_correct =   138, acc = 0.663462, bacc = 0.620766, score = 0.326923\n",
      "Training Epoch  69/275: lr = 1.00E-03, epoch =    69, avg_loss = 0.006348, num_samples =   208, num_correct =   138, acc = 0.663462, bacc = 0.620766, score = 0.326923\n",
      "Evaluation Epoch  69/275: epoch =    69, avg_loss = 0.006113, num_samples =   208, num_correct =   122, acc = 0.586538, bacc = 0.579529, score = 0.173077\n",
      "Training Epoch  70/275: lr = 1.00E-03, epoch =    70, avg_loss = 0.006372, num_samples =   208, num_correct =   114, acc = 0.548077, bacc = 0.558910, score = 0.096154\n",
      "Evaluation Epoch  70/275: epoch =    70, avg_loss = 0.006080, num_samples =   208, num_correct =   122, acc = 0.586538, bacc = 0.579529, score = 0.173077\n",
      "Training Epoch  71/275: lr = 1.00E-03, epoch =    71, avg_loss = 0.006373, num_samples =   208, num_correct =   122, acc = 0.586538, bacc = 0.579529, score = 0.173077\n",
      "Evaluation Epoch  71/275: epoch =    71, avg_loss = 0.005886, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch  72/275: lr = 1.00E-03, epoch =    72, avg_loss = 0.006364, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch  72/275: epoch =    72, avg_loss = 0.005765, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch  73/275: lr = 1.00E-03, epoch =    73, avg_loss = 0.006397, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch  73/275: epoch =    73, avg_loss = 0.005861, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch  74/275: lr = 1.00E-03, epoch =    74, avg_loss = 0.006381, num_samples =   208, num_correct =   138, acc = 0.663462, bacc = 0.620766, score = 0.326923\n",
      "Evaluation Epoch  74/275: epoch =    74, avg_loss = 0.006084, num_samples =   208, num_correct =   114, acc = 0.548077, bacc = 0.558910, score = 0.096154\n",
      "Training Epoch  75/275: lr = 1.00E-03, epoch =    75, avg_loss = 0.006427, num_samples =   208, num_correct =   106, acc = 0.509615, bacc = 0.538292, score = 0.019231\n",
      "Evaluation Epoch  75/275: epoch =    75, avg_loss = 0.006197, num_samples =   208, num_correct =    98, acc = 0.471154, bacc = 0.517673, score = -0.057692\n",
      "Training Epoch  76/275: lr = 1.00E-03, epoch =    76, avg_loss = 0.006413, num_samples =   208, num_correct =    98, acc = 0.471154, bacc = 0.517673, score = -0.057692\n",
      "Evaluation Epoch  76/275: epoch =    76, avg_loss = 0.006102, num_samples =   208, num_correct =   114, acc = 0.548077, bacc = 0.558910, score = 0.096154\n",
      "Training Epoch  77/275: lr = 1.00E-03, epoch =    77, avg_loss = 0.006404, num_samples =   208, num_correct =   114, acc = 0.548077, bacc = 0.558910, score = 0.096154\n",
      "Evaluation Epoch  77/275: epoch =    77, avg_loss = 0.006131, num_samples =   208, num_correct =    98, acc = 0.471154, bacc = 0.517673, score = -0.057692\n",
      "Training Epoch  78/275: lr = 1.00E-03, epoch =    78, avg_loss = 0.006269, num_samples =   208, num_correct =    90, acc = 0.432692, bacc = 0.497054, score = -0.134615\n",
      "Evaluation Epoch  78/275: epoch =    78, avg_loss = 0.006292, num_samples =   208, num_correct =    90, acc = 0.432692, bacc = 0.497054, score = -0.134615\n",
      "Training Epoch  79/275: lr = 1.00E-03, epoch =    79, avg_loss = 0.006386, num_samples =   208, num_correct =    90, acc = 0.432692, bacc = 0.497054, score = -0.134615\n",
      "Evaluation Epoch  79/275: epoch =    79, avg_loss = 0.005993, num_samples =   208, num_correct =   114, acc = 0.548077, bacc = 0.558910, score = 0.096154\n",
      "Training Epoch  80/275: lr = 1.00E-03, epoch =    80, avg_loss = 0.006429, num_samples =   208, num_correct =   130, acc = 0.625000, bacc = 0.600147, score = 0.250000\n",
      "Evaluation Epoch  80/275: epoch =    80, avg_loss = 0.005705, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch  81/275: lr = 1.00E-03, epoch =    81, avg_loss = 0.006411, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch  81/275: epoch =    81, avg_loss = 0.005651, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch  82/275: lr = 1.00E-03, epoch =    82, avg_loss = 0.006388, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch  82/275: epoch =    82, avg_loss = 0.005791, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch  83/275: lr = 1.00E-03, epoch =    83, avg_loss = 0.006368, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch  83/275: epoch =    83, avg_loss = 0.005964, num_samples =   208, num_correct =   130, acc = 0.625000, bacc = 0.600147, score = 0.250000\n",
      "Training Epoch  84/275: lr = 1.00E-03, epoch =    84, avg_loss = 0.006269, num_samples =   208, num_correct =   122, acc = 0.586538, bacc = 0.579529, score = 0.173077\n",
      "Evaluation Epoch  84/275: epoch =    84, avg_loss = 0.006106, num_samples =   208, num_correct =   106, acc = 0.509615, bacc = 0.538292, score = 0.019231\n",
      "Training Epoch  85/275: lr = 1.00E-03, epoch =    85, avg_loss = 0.006343, num_samples =   208, num_correct =   106, acc = 0.509615, bacc = 0.538292, score = 0.019231\n",
      "Evaluation Epoch  85/275: epoch =    85, avg_loss = 0.006097, num_samples =   208, num_correct =   114, acc = 0.548077, bacc = 0.558910, score = 0.096154\n",
      "Training Epoch  86/275: lr = 1.00E-03, epoch =    86, avg_loss = 0.006422, num_samples =   208, num_correct =   114, acc = 0.548077, bacc = 0.558910, score = 0.096154\n",
      "Evaluation Epoch  86/275: epoch =    86, avg_loss = 0.005960, num_samples =   208, num_correct =   130, acc = 0.625000, bacc = 0.600147, score = 0.250000\n",
      "Training Epoch  87/275: lr = 1.00E-03, epoch =    87, avg_loss = 0.006319, num_samples =   208, num_correct =   130, acc = 0.625000, bacc = 0.600147, score = 0.250000\n",
      "Evaluation Epoch  87/275: epoch =    87, avg_loss = 0.005871, num_samples =   208, num_correct =   138, acc = 0.663462, bacc = 0.620766, score = 0.326923\n",
      "Training Epoch  88/275: lr = 1.00E-03, epoch =    88, avg_loss = 0.006314, num_samples =   208, num_correct =   130, acc = 0.625000, bacc = 0.600147, score = 0.250000\n",
      "Evaluation Epoch  88/275: epoch =    88, avg_loss = 0.005812, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch  89/275: lr = 1.00E-03, epoch =    89, avg_loss = 0.006430, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch  89/275: epoch =    89, avg_loss = 0.005752, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch  90/275: lr = 1.00E-03, epoch =    90, avg_loss = 0.006368, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch  90/275: epoch =    90, avg_loss = 0.005930, num_samples =   208, num_correct =   130, acc = 0.625000, bacc = 0.600147, score = 0.250000\n",
      "Training Epoch  91/275: lr = 1.00E-03, epoch =    91, avg_loss = 0.006394, num_samples =   208, num_correct =   114, acc = 0.548077, bacc = 0.558910, score = 0.096154\n",
      "Evaluation Epoch  91/275: epoch =    91, avg_loss = 0.006074, num_samples =   208, num_correct =    98, acc = 0.471154, bacc = 0.517673, score = -0.057692\n",
      "Training Epoch  92/275: lr = 1.00E-03, epoch =    92, avg_loss = 0.006350, num_samples =   208, num_correct =   106, acc = 0.509615, bacc = 0.538292, score = 0.019231\n",
      "Evaluation Epoch  92/275: epoch =    92, avg_loss = 0.006079, num_samples =   208, num_correct =    98, acc = 0.471154, bacc = 0.517673, score = -0.057692\n",
      "Training Epoch  93/275: lr = 1.00E-03, epoch =    93, avg_loss = 0.006379, num_samples =   208, num_correct =    98, acc = 0.471154, bacc = 0.517673, score = -0.057692\n",
      "Evaluation Epoch  93/275: epoch =    93, avg_loss = 0.006008, num_samples =   208, num_correct =   114, acc = 0.548077, bacc = 0.558910, score = 0.096154\n",
      "Training Epoch  94/275: lr = 1.00E-03, epoch =    94, avg_loss = 0.006365, num_samples =   208, num_correct =   114, acc = 0.548077, bacc = 0.558910, score = 0.096154\n",
      "Evaluation Epoch  94/275: epoch =    94, avg_loss = 0.005988, num_samples =   208, num_correct =   114, acc = 0.548077, bacc = 0.558910, score = 0.096154\n",
      "Training Epoch  95/275: lr = 1.00E-03, epoch =    95, avg_loss = 0.006266, num_samples =   208, num_correct =   114, acc = 0.548077, bacc = 0.558910, score = 0.096154\n",
      "Evaluation Epoch  95/275: epoch =    95, avg_loss = 0.006017, num_samples =   208, num_correct =   114, acc = 0.548077, bacc = 0.558910, score = 0.096154\n",
      "Training Epoch  96/275: lr = 1.00E-03, epoch =    96, avg_loss = 0.006333, num_samples =   208, num_correct =   114, acc = 0.548077, bacc = 0.558910, score = 0.096154\n",
      "Evaluation Epoch  96/275: epoch =    96, avg_loss = 0.005996, num_samples =   208, num_correct =   114, acc = 0.548077, bacc = 0.558910, score = 0.096154\n",
      "Training Epoch  97/275: lr = 1.00E-03, epoch =    97, avg_loss = 0.006164, num_samples =   208, num_correct =   106, acc = 0.509615, bacc = 0.538292, score = 0.019231\n",
      "Evaluation Epoch  97/275: epoch =    97, avg_loss = 0.006060, num_samples =   208, num_correct =    90, acc = 0.432692, bacc = 0.497054, score = -0.134615\n",
      "Training Epoch  98/275: lr = 1.00E-03, epoch =    98, avg_loss = 0.006327, num_samples =   208, num_correct =    98, acc = 0.471154, bacc = 0.517673, score = -0.057692\n",
      "Evaluation Epoch  98/275: epoch =    98, avg_loss = 0.005975, num_samples =   208, num_correct =   122, acc = 0.586538, bacc = 0.579529, score = 0.173077\n",
      "Training Epoch  99/275: lr = 1.00E-03, epoch =    99, avg_loss = 0.006384, num_samples =   208, num_correct =   138, acc = 0.663462, bacc = 0.620766, score = 0.326923\n",
      "Evaluation Epoch  99/275: epoch =    99, avg_loss = 0.005996, num_samples =   208, num_correct =   122, acc = 0.586538, bacc = 0.579529, score = 0.173077\n",
      "Training Epoch 100/275: lr = 1.00E-03, epoch =   100, avg_loss = 0.006225, num_samples =   208, num_correct =    98, acc = 0.471154, bacc = 0.517673, score = -0.057692\n",
      "Evaluation Epoch 100/275: epoch =   100, avg_loss = 0.006037, num_samples =   208, num_correct =   106, acc = 0.509615, bacc = 0.538292, score = 0.019231\n",
      "Training Epoch 101/275: lr = 1.00E-03, epoch =   101, avg_loss = 0.006389, num_samples =   208, num_correct =   130, acc = 0.625000, bacc = 0.600147, score = 0.250000\n",
      "Evaluation Epoch 101/275: epoch =   101, avg_loss = 0.005844, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 102/275: lr = 1.00E-03, epoch =   102, avg_loss = 0.006313, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 102/275: epoch =   102, avg_loss = 0.005965, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 103/275: lr = 1.00E-03, epoch =   103, avg_loss = 0.006341, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 103/275: epoch =   103, avg_loss = 0.005940, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 104/275: lr = 1.00E-03, epoch =   104, avg_loss = 0.006416, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 104/275: epoch =   104, avg_loss = 0.005880, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 105/275: lr = 1.00E-03, epoch =   105, avg_loss = 0.006384, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 105/275: epoch =   105, avg_loss = 0.006051, num_samples =   208, num_correct =   138, acc = 0.663462, bacc = 0.620766, score = 0.326923\n",
      "Training Epoch 106/275: lr = 1.00E-03, epoch =   106, avg_loss = 0.006308, num_samples =   208, num_correct =   138, acc = 0.663462, bacc = 0.620766, score = 0.326923\n",
      "Evaluation Epoch 106/275: epoch =   106, avg_loss = 0.006025, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 107/275: lr = 1.00E-03, epoch =   107, avg_loss = 0.006267, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 107/275: epoch =   107, avg_loss = 0.005925, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 108/275: lr = 1.00E-03, epoch =   108, avg_loss = 0.006329, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 108/275: epoch =   108, avg_loss = 0.005759, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 109/275: lr = 1.00E-03, epoch =   109, avg_loss = 0.006398, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 109/275: epoch =   109, avg_loss = 0.005910, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 110/275: lr = 1.00E-03, epoch =   110, avg_loss = 0.006364, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 110/275: epoch =   110, avg_loss = 0.006190, num_samples =   208, num_correct =    90, acc = 0.432692, bacc = 0.497054, score = -0.134615\n",
      "Training Epoch 111/275: lr = 1.00E-03, epoch =   111, avg_loss = 0.006362, num_samples =   208, num_correct =    90, acc = 0.432692, bacc = 0.497054, score = -0.134615\n",
      "Evaluation Epoch 111/275: epoch =   111, avg_loss = 0.006142, num_samples =   208, num_correct =    90, acc = 0.432692, bacc = 0.497054, score = -0.134615\n",
      "Training Epoch 112/275: lr = 1.00E-03, epoch =   112, avg_loss = 0.006233, num_samples =   208, num_correct =   114, acc = 0.548077, bacc = 0.558910, score = 0.096154\n",
      "Evaluation Epoch 112/275: epoch =   112, avg_loss = 0.005808, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 113/275: lr = 1.00E-03, epoch =   113, avg_loss = 0.006312, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 113/275: epoch =   113, avg_loss = 0.005662, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 114/275: lr = 1.00E-03, epoch =   114, avg_loss = 0.006281, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 114/275: epoch =   114, avg_loss = 0.005947, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 115/275: lr = 1.00E-03, epoch =   115, avg_loss = 0.006281, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 115/275: epoch =   115, avg_loss = 0.005992, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 116/275: lr = 1.00E-03, epoch =   116, avg_loss = 0.006330, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 116/275: epoch =   116, avg_loss = 0.005896, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 117/275: lr = 1.00E-03, epoch =   117, avg_loss = 0.006240, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 117/275: epoch =   117, avg_loss = 0.005758, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 118/275: lr = 1.00E-03, epoch =   118, avg_loss = 0.006249, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 118/275: epoch =   118, avg_loss = 0.005892, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 119/275: lr = 1.00E-03, epoch =   119, avg_loss = 0.006253, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 119/275: epoch =   119, avg_loss = 0.006081, num_samples =   208, num_correct =   130, acc = 0.625000, bacc = 0.600147, score = 0.250000\n",
      "Training Epoch 120/275: lr = 1.00E-03, epoch =   120, avg_loss = 0.006238, num_samples =   208, num_correct =   138, acc = 0.663462, bacc = 0.620766, score = 0.326923\n",
      "Evaluation Epoch 120/275: epoch =   120, avg_loss = 0.005840, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 121/275: lr = 1.00E-03, epoch =   121, avg_loss = 0.006319, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 121/275: epoch =   121, avg_loss = 0.005758, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 122/275: lr = 1.00E-03, epoch =   122, avg_loss = 0.006223, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 122/275: epoch =   122, avg_loss = 0.006016, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 123/275: lr = 1.00E-03, epoch =   123, avg_loss = 0.006243, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 123/275: epoch =   123, avg_loss = 0.006091, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 124/275: lr = 1.00E-03, epoch =   124, avg_loss = 0.006285, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 124/275: epoch =   124, avg_loss = 0.005939, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 125/275: lr = 1.00E-03, epoch =   125, avg_loss = 0.006076, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 125/275: epoch =   125, avg_loss = 0.005687, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 126/275: lr = 1.00E-03, epoch =   126, avg_loss = 0.006261, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 126/275: epoch =   126, avg_loss = 0.005798, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 127/275: lr = 1.00E-03, epoch =   127, avg_loss = 0.006177, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 127/275: epoch =   127, avg_loss = 0.006039, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 128/275: lr = 1.00E-03, epoch =   128, avg_loss = 0.006241, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 128/275: epoch =   128, avg_loss = 0.005905, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 129/275: lr = 1.00E-03, epoch =   129, avg_loss = 0.006117, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 129/275: epoch =   129, avg_loss = 0.005520, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 130/275: lr = 1.00E-03, epoch =   130, avg_loss = 0.006289, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 130/275: epoch =   130, avg_loss = 0.005532, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 131/275: lr = 1.00E-03, epoch =   131, avg_loss = 0.006169, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 131/275: epoch =   131, avg_loss = 0.005996, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 132/275: lr = 1.00E-03, epoch =   132, avg_loss = 0.006206, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 132/275: epoch =   132, avg_loss = 0.006085, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 133/275: lr = 1.00E-03, epoch =   133, avg_loss = 0.006225, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 133/275: epoch =   133, avg_loss = 0.005837, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 134/275: lr = 1.00E-03, epoch =   134, avg_loss = 0.006020, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 134/275: epoch =   134, avg_loss = 0.005579, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 135/275: lr = 1.00E-03, epoch =   135, avg_loss = 0.006201, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 135/275: epoch =   135, avg_loss = 0.005293, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 136/275: lr = 1.00E-03, epoch =   136, avg_loss = 0.006269, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 136/275: epoch =   136, avg_loss = 0.005633, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 137/275: lr = 1.00E-03, epoch =   137, avg_loss = 0.005932, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 137/275: epoch =   137, avg_loss = 0.006025, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 138/275: lr = 1.00E-03, epoch =   138, avg_loss = 0.006171, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 138/275: epoch =   138, avg_loss = 0.006003, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 139/275: lr = 1.00E-03, epoch =   139, avg_loss = 0.006091, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 139/275: epoch =   139, avg_loss = 0.005781, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 140/275: lr = 1.00E-03, epoch =   140, avg_loss = 0.005697, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 140/275: epoch =   140, avg_loss = 0.005352, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 141/275: lr = 1.00E-03, epoch =   141, avg_loss = 0.005994, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 141/275: epoch =   141, avg_loss = 0.005311, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 142/275: lr = 1.00E-03, epoch =   142, avg_loss = 0.006128, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 142/275: epoch =   142, avg_loss = 0.005550, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 143/275: lr = 1.00E-03, epoch =   143, avg_loss = 0.006117, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 143/275: epoch =   143, avg_loss = 0.005768, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 144/275: lr = 1.00E-03, epoch =   144, avg_loss = 0.006180, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 144/275: epoch =   144, avg_loss = 0.005640, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 145/275: lr = 1.00E-03, epoch =   145, avg_loss = 0.006111, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 145/275: epoch =   145, avg_loss = 0.005334, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 146/275: lr = 1.00E-03, epoch =   146, avg_loss = 0.005975, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 146/275: epoch =   146, avg_loss = 0.005235, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 147/275: lr = 1.00E-03, epoch =   147, avg_loss = 0.006096, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 147/275: epoch =   147, avg_loss = 0.005537, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 148/275: lr = 1.00E-03, epoch =   148, avg_loss = 0.005912, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 148/275: epoch =   148, avg_loss = 0.005668, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 149/275: lr = 1.00E-03, epoch =   149, avg_loss = 0.006030, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 149/275: epoch =   149, avg_loss = 0.005557, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 150/275: lr = 1.00E-03, epoch =   150, avg_loss = 0.005754, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 150/275: epoch =   150, avg_loss = 0.005344, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 151/275: lr = 1.00E-03, epoch =   151, avg_loss = 0.005902, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 151/275: epoch =   151, avg_loss = 0.005608, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 152/275: lr = 1.00E-03, epoch =   152, avg_loss = 0.005993, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 152/275: epoch =   152, avg_loss = 0.005766, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 153/275: lr = 1.00E-03, epoch =   153, avg_loss = 0.006039, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 153/275: epoch =   153, avg_loss = 0.005493, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 154/275: lr = 1.00E-03, epoch =   154, avg_loss = 0.005854, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 154/275: epoch =   154, avg_loss = 0.005160, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 155/275: lr = 1.00E-03, epoch =   155, avg_loss = 0.005887, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 155/275: epoch =   155, avg_loss = 0.005407, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 156/275: lr = 1.00E-03, epoch =   156, avg_loss = 0.005938, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 156/275: epoch =   156, avg_loss = 0.005600, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 157/275: lr = 1.00E-03, epoch =   157, avg_loss = 0.005977, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 157/275: epoch =   157, avg_loss = 0.005597, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 158/275: lr = 1.00E-03, epoch =   158, avg_loss = 0.005973, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 158/275: epoch =   158, avg_loss = 0.005478, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 159/275: lr = 1.00E-03, epoch =   159, avg_loss = 0.005862, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 159/275: epoch =   159, avg_loss = 0.005562, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 160/275: lr = 1.00E-03, epoch =   160, avg_loss = 0.005909, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 160/275: epoch =   160, avg_loss = 0.005687, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 161/275: lr = 1.00E-03, epoch =   161, avg_loss = 0.005923, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 161/275: epoch =   161, avg_loss = 0.005518, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 162/275: lr = 1.00E-03, epoch =   162, avg_loss = 0.005807, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 162/275: epoch =   162, avg_loss = 0.005386, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 163/275: lr = 1.00E-03, epoch =   163, avg_loss = 0.005829, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 163/275: epoch =   163, avg_loss = 0.005464, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 164/275: lr = 1.00E-03, epoch =   164, avg_loss = 0.005841, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 164/275: epoch =   164, avg_loss = 0.005509, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 165/275: lr = 1.00E-03, epoch =   165, avg_loss = 0.005541, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 165/275: epoch =   165, avg_loss = 0.005446, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 166/275: lr = 1.00E-03, epoch =   166, avg_loss = 0.005787, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 166/275: epoch =   166, avg_loss = 0.005669, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 167/275: lr = 1.00E-03, epoch =   167, avg_loss = 0.005720, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 167/275: epoch =   167, avg_loss = 0.005453, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 168/275: lr = 1.00E-03, epoch =   168, avg_loss = 0.005687, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 168/275: epoch =   168, avg_loss = 0.005311, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 169/275: lr = 1.00E-03, epoch =   169, avg_loss = 0.005613, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 169/275: epoch =   169, avg_loss = 0.005396, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 170/275: lr = 1.00E-03, epoch =   170, avg_loss = 0.005654, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Evaluation Epoch 170/275: epoch =   170, avg_loss = 0.005384, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846\n",
      "Training Epoch 171/275: lr = 1.00E-03, epoch =   171, avg_loss = 0.005592, num_samples =   208, num_correct =   128, acc = 0.615385, bacc = 0.694404, score = 0.230769\n",
      "Evaluation Epoch 171/275: epoch =   171, avg_loss = 0.005351, num_samples =   208, num_correct =   134, acc = 0.644231, bacc = 0.676730, score = 0.288462\n",
      "Training Epoch 172/275: lr = 1.00E-03, epoch =   172, avg_loss = 0.005454, num_samples =   208, num_correct =   128, acc = 0.615385, bacc = 0.694404, score = 0.230769\n",
      "Evaluation Epoch 172/275: epoch =   172, avg_loss = 0.005561, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Training Epoch 173/275: lr = 1.00E-03, epoch =   173, avg_loss = 0.005419, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Evaluation Epoch 173/275: epoch =   173, avg_loss = 0.005356, num_samples =   208, num_correct =   122, acc = 0.586538, bacc = 0.712077, score = 0.173077\n",
      "Training Epoch 174/275: lr = 1.00E-03, epoch =   174, avg_loss = 0.005473, num_samples =   208, num_correct =   116, acc = 0.557692, bacc = 0.729750, score = 0.115385\n",
      "Evaluation Epoch 174/275: epoch =   174, avg_loss = 0.005403, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Training Epoch 175/275: lr = 1.00E-03, epoch =   175, avg_loss = 0.005490, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Evaluation Epoch 175/275: epoch =   175, avg_loss = 0.005228, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Training Epoch 176/275: lr = 1.00E-03, epoch =   176, avg_loss = 0.005401, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Evaluation Epoch 176/275: epoch =   176, avg_loss = 0.005134, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Training Epoch 177/275: lr = 1.00E-03, epoch =   177, avg_loss = 0.005432, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Evaluation Epoch 177/275: epoch =   177, avg_loss = 0.005400, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Training Epoch 178/275: lr = 1.00E-03, epoch =   178, avg_loss = 0.005357, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Evaluation Epoch 178/275: epoch =   178, avg_loss = 0.005265, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Training Epoch 179/275: lr = 1.00E-03, epoch =   179, avg_loss = 0.005379, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Evaluation Epoch 179/275: epoch =   179, avg_loss = 0.005126, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Training Epoch 180/275: lr = 1.00E-03, epoch =   180, avg_loss = 0.005316, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Evaluation Epoch 180/275: epoch =   180, avg_loss = 0.005323, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Training Epoch 181/275: lr = 1.00E-03, epoch =   181, avg_loss = 0.005251, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Evaluation Epoch 181/275: epoch =   181, avg_loss = 0.005419, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Training Epoch 182/275: lr = 1.00E-03, epoch =   182, avg_loss = 0.005117, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Evaluation Epoch 182/275: epoch =   182, avg_loss = 0.005359, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Training Epoch 183/275: lr = 1.00E-03, epoch =   183, avg_loss = 0.005080, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Evaluation Epoch 183/275: epoch =   183, avg_loss = 0.005432, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Training Epoch 184/275: lr = 1.00E-03, epoch =   184, avg_loss = 0.005130, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Evaluation Epoch 184/275: epoch =   184, avg_loss = 0.005269, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Training Epoch 185/275: lr = 1.00E-03, epoch =   185, avg_loss = 0.005011, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Evaluation Epoch 185/275: epoch =   185, avg_loss = 0.005196, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Training Epoch 186/275: lr = 1.00E-03, epoch =   186, avg_loss = 0.005039, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Evaluation Epoch 186/275: epoch =   186, avg_loss = 0.005125, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Training Epoch 187/275: lr = 1.00E-03, epoch =   187, avg_loss = 0.004902, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Evaluation Epoch 187/275: epoch =   187, avg_loss = 0.005170, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Training Epoch 188/275: lr = 1.00E-03, epoch =   188, avg_loss = 0.004944, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Evaluation Epoch 188/275: epoch =   188, avg_loss = 0.005275, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Training Epoch 189/275: lr = 1.00E-03, epoch =   189, avg_loss = 0.004909, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Evaluation Epoch 189/275: epoch =   189, avg_loss = 0.005384, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Training Epoch 190/275: lr = 1.00E-03, epoch =   190, avg_loss = 0.004673, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Evaluation Epoch 190/275: epoch =   190, avg_loss = 0.005310, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Training Epoch 191/275: lr = 1.00E-03, epoch =   191, avg_loss = 0.004845, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Evaluation Epoch 191/275: epoch =   191, avg_loss = 0.005140, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Training Epoch 192/275: lr = 1.00E-03, epoch =   192, avg_loss = 0.004375, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Evaluation Epoch 192/275: epoch =   192, avg_loss = 0.004982, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Training Epoch 193/275: lr = 1.00E-03, epoch =   193, avg_loss = 0.004781, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Evaluation Epoch 193/275: epoch =   193, avg_loss = 0.005184, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Training Epoch 194/275: lr = 1.00E-03, epoch =   194, avg_loss = 0.004759, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Evaluation Epoch 194/275: epoch =   194, avg_loss = 0.005085, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Training Epoch 195/275: lr = 1.00E-03, epoch =   195, avg_loss = 0.004024, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Evaluation Epoch 195/275: epoch =   195, avg_loss = 0.004949, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Training Epoch 196/275: lr = 1.00E-03, epoch =   196, avg_loss = 0.004800, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Evaluation Epoch 196/275: epoch =   196, avg_loss = 0.005017, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Training Epoch 197/275: lr = 1.00E-03, epoch =   197, avg_loss = 0.004782, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Evaluation Epoch 197/275: epoch =   197, avg_loss = 0.005492, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Training Epoch 198/275: lr = 1.00E-03, epoch =   198, avg_loss = 0.004659, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Evaluation Epoch 198/275: epoch =   198, avg_loss = 0.005804, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Training Epoch 199/275: lr = 1.00E-03, epoch =   199, avg_loss = 0.004756, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Evaluation Epoch 199/275: epoch =   199, avg_loss = 0.004950, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Training Epoch 200/275: lr = 1.00E-03, epoch =   200, avg_loss = 0.004490, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Evaluation Epoch 200/275: epoch =   200, avg_loss = 0.004398, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Training Epoch 201/275: lr = 1.00E-03, epoch =   201, avg_loss = 0.004661, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Evaluation Epoch 201/275: epoch =   201, avg_loss = 0.005169, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Training Epoch 202/275: lr = 1.00E-03, epoch =   202, avg_loss = 0.004717, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Evaluation Epoch 202/275: epoch =   202, avg_loss = 0.005820, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Training Epoch 203/275: lr = 1.00E-03, epoch =   203, avg_loss = 0.004685, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Evaluation Epoch 203/275: epoch =   203, avg_loss = 0.005346, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Training Epoch 204/275: lr = 1.00E-03, epoch =   204, avg_loss = 0.004674, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Evaluation Epoch 204/275: epoch =   204, avg_loss = 0.004991, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Training Epoch 205/275: lr = 1.00E-03, epoch =   205, avg_loss = 0.004432, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Evaluation Epoch 205/275: epoch =   205, avg_loss = 0.004725, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Training Epoch 206/275: lr = 1.00E-03, epoch =   206, avg_loss = 0.004695, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Evaluation Epoch 206/275: epoch =   206, avg_loss = 0.005274, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Training Epoch 207/275: lr = 1.00E-03, epoch =   207, avg_loss = 0.004577, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Evaluation Epoch 207/275: epoch =   207, avg_loss = 0.005488, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Training Epoch 208/275: lr = 1.00E-03, epoch =   208, avg_loss = 0.004582, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Evaluation Epoch 208/275: epoch =   208, avg_loss = 0.004904, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Training Epoch 209/275: lr = 1.00E-03, epoch =   209, avg_loss = 0.004506, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Evaluation Epoch 209/275: epoch =   209, avg_loss = 0.004334, num_samples =   208, num_correct =   140, acc = 0.673077, bacc = 0.824742, score = 0.346154\n",
      "Training Epoch 210/275: lr = 1.00E-03, epoch =   210, avg_loss = 0.004456, num_samples =   208, num_correct =   135, acc = 0.649038, bacc = 0.811856, score = 0.298077\n",
      "Evaluation Epoch 210/275: epoch =   210, avg_loss = 0.004502, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692\n",
      "Training Epoch 211/275: lr = 1.00E-03, epoch =   211, avg_loss = 0.004101, num_samples =   208, num_correct =   117, acc = 0.562500, bacc = 0.765464, score = 0.125000\n",
      "Evaluation Epoch 211/275: epoch =   211, avg_loss = 0.004621, num_samples =   208, num_correct =   117, acc = 0.562500, bacc = 0.765464, score = 0.125000\n",
      "Training Epoch 212/275: lr = 1.00E-03, epoch =   212, avg_loss = 0.003636, num_samples =   208, num_correct =   126, acc = 0.605769, bacc = 0.788660, score = 0.211538\n",
      "Evaluation Epoch 212/275: epoch =   212, avg_loss = 0.004135, num_samples =   208, num_correct =   140, acc = 0.673077, bacc = 0.824742, score = 0.346154\n",
      "Training Epoch 213/275: lr = 1.00E-03, epoch =   213, avg_loss = 0.003333, num_samples =   208, num_correct =   147, acc = 0.706731, bacc = 0.842784, score = 0.413462\n",
      "Evaluation Epoch 213/275: epoch =   213, avg_loss = 0.003158, num_samples =   208, num_correct =   182, acc = 0.875000, bacc = 0.932990, score = 0.750000\n",
      "Training Epoch 214/275: lr = 1.00E-03, epoch =   214, avg_loss = 0.002583, num_samples =   208, num_correct =   189, acc = 0.908654, bacc = 0.951031, score = 0.817308\n",
      "Evaluation Epoch 214/275: epoch =   214, avg_loss = 0.002340, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 215/275: lr = 1.00E-03, epoch =   215, avg_loss = 0.001889, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 215/275: epoch =   215, avg_loss = 0.002071, num_samples =   208, num_correct =   193, acc = 0.927885, bacc = 0.961340, score = 0.855769\n",
      "Training Epoch 216/275: lr = 1.00E-03, epoch =   216, avg_loss = 0.001346, num_samples =   208, num_correct =   193, acc = 0.927885, bacc = 0.961340, score = 0.855769\n",
      "Evaluation Epoch 216/275: epoch =   216, avg_loss = 0.002022, num_samples =   208, num_correct =   193, acc = 0.927885, bacc = 0.961340, score = 0.855769\n",
      "Training Epoch 217/275: lr = 1.00E-03, epoch =   217, avg_loss = 0.001295, num_samples =   208, num_correct =   193, acc = 0.927885, bacc = 0.961340, score = 0.855769\n",
      "Evaluation Epoch 217/275: epoch =   217, avg_loss = 0.001468, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 218/275: lr = 1.00E-03, epoch =   218, avg_loss = 0.001092, num_samples =   208, num_correct =   193, acc = 0.927885, bacc = 0.961340, score = 0.855769\n",
      "Evaluation Epoch 218/275: epoch =   218, avg_loss = 0.001789, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.963918, score = 0.865385\n",
      "Training Epoch 219/275: lr = 1.00E-03, epoch =   219, avg_loss = 0.001005, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.963918, score = 0.865385\n",
      "Evaluation Epoch 219/275: epoch =   219, avg_loss = 0.001560, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 220/275: lr = 1.00E-03, epoch =   220, avg_loss = 0.000854, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 220/275: epoch =   220, avg_loss = 0.001449, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 221/275: lr = 1.00E-03, epoch =   221, avg_loss = 0.000925, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 221/275: epoch =   221, avg_loss = 0.001364, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 222/275: lr = 1.00E-03, epoch =   222, avg_loss = 0.000953, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 222/275: epoch =   222, avg_loss = 0.001318, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 223/275: lr = 1.00E-03, epoch =   223, avg_loss = 0.000938, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 223/275: epoch =   223, avg_loss = 0.001334, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 224/275: lr = 1.00E-03, epoch =   224, avg_loss = 0.001008, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 224/275: epoch =   224, avg_loss = 0.001341, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 225/275: lr = 1.00E-03, epoch =   225, avg_loss = 0.000692, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 225/275: epoch =   225, avg_loss = 0.001359, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 226/275: lr = 1.00E-03, epoch =   226, avg_loss = 0.000959, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 226/275: epoch =   226, avg_loss = 0.001630, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 227/275: lr = 1.00E-03, epoch =   227, avg_loss = 0.000903, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 227/275: epoch =   227, avg_loss = 0.001462, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 228/275: lr = 1.00E-03, epoch =   228, avg_loss = 0.000848, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 228/275: epoch =   228, avg_loss = 0.001636, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 229/275: lr = 1.00E-03, epoch =   229, avg_loss = 0.000803, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 229/275: epoch =   229, avg_loss = 0.001208, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 230/275: lr = 1.00E-03, epoch =   230, avg_loss = 0.000967, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 230/275: epoch =   230, avg_loss = 0.001653, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 231/275: lr = 1.00E-03, epoch =   231, avg_loss = 0.000917, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 231/275: epoch =   231, avg_loss = 0.001542, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 232/275: lr = 1.00E-03, epoch =   232, avg_loss = 0.000821, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 232/275: epoch =   232, avg_loss = 0.001123, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 233/275: lr = 1.00E-03, epoch =   233, avg_loss = 0.001097, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 233/275: epoch =   233, avg_loss = 0.001669, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 234/275: lr = 1.00E-03, epoch =   234, avg_loss = 0.000831, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 234/275: epoch =   234, avg_loss = 0.001100, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 235/275: lr = 1.00E-03, epoch =   235, avg_loss = 0.000854, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 235/275: epoch =   235, avg_loss = 0.001699, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 236/275: lr = 1.00E-03, epoch =   236, avg_loss = 0.000642, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 236/275: epoch =   236, avg_loss = 0.001537, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 237/275: lr = 1.00E-03, epoch =   237, avg_loss = 0.001044, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 237/275: epoch =   237, avg_loss = 0.001657, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 238/275: lr = 1.00E-03, epoch =   238, avg_loss = 0.000958, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 238/275: epoch =   238, avg_loss = 0.001526, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 239/275: lr = 1.00E-03, epoch =   239, avg_loss = 0.000884, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 239/275: epoch =   239, avg_loss = 0.001122, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 240/275: lr = 1.00E-03, epoch =   240, avg_loss = 0.000972, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 240/275: epoch =   240, avg_loss = 0.001605, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 241/275: lr = 1.00E-03, epoch =   241, avg_loss = 0.001126, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 241/275: epoch =   241, avg_loss = 0.001271, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 242/275: lr = 1.00E-03, epoch =   242, avg_loss = 0.000732, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 242/275: epoch =   242, avg_loss = 0.001602, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 243/275: lr = 1.00E-03, epoch =   243, avg_loss = 0.000919, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 243/275: epoch =   243, avg_loss = 0.001666, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 244/275: lr = 1.00E-03, epoch =   244, avg_loss = 0.000900, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 244/275: epoch =   244, avg_loss = 0.001584, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 245/275: lr = 1.00E-03, epoch =   245, avg_loss = 0.000970, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 245/275: epoch =   245, avg_loss = 0.001426, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 246/275: lr = 1.00E-03, epoch =   246, avg_loss = 0.000798, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 246/275: epoch =   246, avg_loss = 0.001307, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 247/275: lr = 1.00E-03, epoch =   247, avg_loss = 0.000898, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 247/275: epoch =   247, avg_loss = 0.001287, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 248/275: lr = 1.00E-03, epoch =   248, avg_loss = 0.000802, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 248/275: epoch =   248, avg_loss = 0.001410, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 249/275: lr = 1.00E-03, epoch =   249, avg_loss = 0.000882, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 249/275: epoch =   249, avg_loss = 0.001423, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 250/275: lr = 1.00E-03, epoch =   250, avg_loss = 0.000993, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 250/275: epoch =   250, avg_loss = 0.001463, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 251/275: lr = 1.00E-03, epoch =   251, avg_loss = 0.000881, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 251/275: epoch =   251, avg_loss = 0.001536, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 252/275: lr = 1.00E-03, epoch =   252, avg_loss = 0.000818, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 252/275: epoch =   252, avg_loss = 0.001415, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 253/275: lr = 1.00E-03, epoch =   253, avg_loss = 0.000910, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 253/275: epoch =   253, avg_loss = 0.001471, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 254/275: lr = 1.00E-03, epoch =   254, avg_loss = 0.000891, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 254/275: epoch =   254, avg_loss = 0.001513, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 255/275: lr = 1.00E-03, epoch =   255, avg_loss = 0.000814, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 255/275: epoch =   255, avg_loss = 0.001560, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 256/275: lr = 1.00E-03, epoch =   256, avg_loss = 0.000875, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 256/275: epoch =   256, avg_loss = 0.001383, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 257/275: lr = 1.00E-03, epoch =   257, avg_loss = 0.000871, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 257/275: epoch =   257, avg_loss = 0.001280, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 258/275: lr = 1.00E-03, epoch =   258, avg_loss = 0.000918, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 258/275: epoch =   258, avg_loss = 0.001219, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 259/275: lr = 1.00E-03, epoch =   259, avg_loss = 0.000895, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 259/275: epoch =   259, avg_loss = 0.001598, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 260/275: lr = 1.00E-03, epoch =   260, avg_loss = 0.000713, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 260/275: epoch =   260, avg_loss = 0.001715, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 261/275: lr = 1.00E-03, epoch =   261, avg_loss = 0.000802, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 261/275: epoch =   261, avg_loss = 0.001267, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 262/275: lr = 1.00E-03, epoch =   262, avg_loss = 0.000875, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 262/275: epoch =   262, avg_loss = 0.001486, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 263/275: lr = 1.00E-03, epoch =   263, avg_loss = 0.000873, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 263/275: epoch =   263, avg_loss = 0.001463, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 264/275: lr = 1.00E-03, epoch =   264, avg_loss = 0.000887, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 264/275: epoch =   264, avg_loss = 0.001322, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 265/275: lr = 1.00E-03, epoch =   265, avg_loss = 0.000849, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 265/275: epoch =   265, avg_loss = 0.001168, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 266/275: lr = 1.00E-03, epoch =   266, avg_loss = 0.000874, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 266/275: epoch =   266, avg_loss = 0.001404, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 267/275: lr = 1.00E-03, epoch =   267, avg_loss = 0.000771, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 267/275: epoch =   267, avg_loss = 0.001467, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 268/275: lr = 1.00E-03, epoch =   268, avg_loss = 0.000913, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 268/275: epoch =   268, avg_loss = 0.001473, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 269/275: lr = 1.00E-03, epoch =   269, avg_loss = 0.000964, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 269/275: epoch =   269, avg_loss = 0.001612, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 270/275: lr = 1.00E-03, epoch =   270, avg_loss = 0.000826, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 270/275: epoch =   270, avg_loss = 0.001522, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 271/275: lr = 1.00E-03, epoch =   271, avg_loss = 0.000785, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 271/275: epoch =   271, avg_loss = 0.000856, num_samples =   208, num_correct =   198, acc = 0.951923, bacc = 0.974227, score = 0.903846\n",
      "Training Epoch 272/275: lr = 1.00E-03, epoch =   272, avg_loss = 0.000915, num_samples =   208, num_correct =   197, acc = 0.947115, bacc = 0.971649, score = 0.894231\n",
      "Evaluation Epoch 272/275: epoch =   272, avg_loss = 0.001520, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 273/275: lr = 1.00E-03, epoch =   273, avg_loss = 0.001057, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 273/275: epoch =   273, avg_loss = 0.001600, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 274/275: lr = 1.00E-03, epoch =   274, avg_loss = 0.001019, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 274/275: epoch =   274, avg_loss = 0.001851, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training Epoch 275/275: lr = 1.00E-03, epoch =   275, avg_loss = 0.000985, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Evaluation Epoch 275/275: epoch =   275, avg_loss = 0.001766, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615\n",
      "Training finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(AttentionClassifier(\n",
       "   (in_fnn): FNN(\n",
       "     (layers): Sequential(\n",
       "       (0): Dropout(p=0.45, inplace=False)\n",
       "       (1): Linear(in_features=1, out_features=128, bias=True)\n",
       "       (2): LeakyReLU(negative_slope=0.01)\n",
       "       (3): Dropout(p=0.45, inplace=False)\n",
       "       (4): Linear(in_features=128, out_features=64, bias=True)\n",
       "       (5): LeakyReLU(negative_slope=0.01)\n",
       "       (6): Dropout(p=0.45, inplace=False)\n",
       "       (7): Linear(in_features=64, out_features=64, bias=True)\n",
       "       (8): LeakyReLU(negative_slope=0.01)\n",
       "       (9): Dropout(p=0.45, inplace=False)\n",
       "       (10): Linear(in_features=64, out_features=64, bias=True)\n",
       "     )\n",
       "   )\n",
       "   (positional_encoder): PositionalEncoding()\n",
       "   (attention_stack): Sequential(\n",
       "     (0): MultiheadSelfAttention(\n",
       "       (multihead_attention): MultiheadAttention(\n",
       "         (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "       )\n",
       "     )\n",
       "     (1): LeakyReLU(negative_slope=0.01)\n",
       "     (2): MultiheadSelfAttention(\n",
       "       (multihead_attention): MultiheadAttention(\n",
       "         (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (out_fnn): FNN(\n",
       "     (layers): Sequential(\n",
       "       (0): Dropout(p=0.45, inplace=False)\n",
       "       (1): Linear(in_features=64, out_features=32, bias=True)\n",
       "       (2): LeakyReLU(negative_slope=0.01)\n",
       "       (3): Dropout(p=0.45, inplace=False)\n",
       "       (4): Linear(in_features=32, out_features=16, bias=True)\n",
       "       (5): LeakyReLU(negative_slope=0.01)\n",
       "       (6): Dropout(p=0.45, inplace=False)\n",
       "       (7): Linear(in_features=16, out_features=2, bias=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " [(epoch =     1, avg_loss = 0.006668, num_samples =   208, num_correct =   164, acc = 0.788462, bacc = 0.455817, score = 0.576923,\n",
       "   epoch =     1, avg_loss = 0.006431, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385),\n",
       "  (epoch =     2, avg_loss = 0.006673, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385,\n",
       "   epoch =     2, avg_loss = 0.006463, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385),\n",
       "  (epoch =     3, avg_loss = 0.006662, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385,\n",
       "   epoch =     3, avg_loss = 0.006507, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385),\n",
       "  (epoch =     4, avg_loss = 0.006665, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385,\n",
       "   epoch =     4, avg_loss = 0.006528, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385),\n",
       "  (epoch =     5, avg_loss = 0.006665, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385,\n",
       "   epoch =     5, avg_loss = 0.006548, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385),\n",
       "  (epoch =     6, avg_loss = 0.006668, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385,\n",
       "   epoch =     6, avg_loss = 0.006556, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385),\n",
       "  (epoch =     7, avg_loss = 0.006666, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385,\n",
       "   epoch =     7, avg_loss = 0.006581, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385),\n",
       "  (epoch =     8, avg_loss = 0.006665, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385,\n",
       "   epoch =     8, avg_loss = 0.006612, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385),\n",
       "  (epoch =     9, avg_loss = 0.006664, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385,\n",
       "   epoch =     9, avg_loss = 0.006636, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385),\n",
       "  (epoch =    10, avg_loss = 0.006665, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385,\n",
       "   epoch =    10, avg_loss = 0.006638, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385),\n",
       "  (epoch =    11, avg_loss = 0.006666, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385,\n",
       "   epoch =    11, avg_loss = 0.006639, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385),\n",
       "  (epoch =    12, avg_loss = 0.006665, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385,\n",
       "   epoch =    12, avg_loss = 0.006654, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385),\n",
       "  (epoch =    13, avg_loss = 0.006664, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.500000, score = 0.865385,\n",
       "   epoch =    13, avg_loss = 0.006671, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385),\n",
       "  (epoch =    14, avg_loss = 0.006665, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385,\n",
       "   epoch =    14, avg_loss = 0.006691, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385),\n",
       "  (epoch =    15, avg_loss = 0.006665, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385,\n",
       "   epoch =    15, avg_loss = 0.006692, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385),\n",
       "  (epoch =    16, avg_loss = 0.006665, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385,\n",
       "   epoch =    16, avg_loss = 0.006706, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385),\n",
       "  (epoch =    17, avg_loss = 0.006664, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385,\n",
       "   epoch =    17, avg_loss = 0.006710, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385),\n",
       "  (epoch =    18, avg_loss = 0.006665, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385,\n",
       "   epoch =    18, avg_loss = 0.006718, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385),\n",
       "  (epoch =    19, avg_loss = 0.006664, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385,\n",
       "   epoch =    19, avg_loss = 0.006713, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385),\n",
       "  (epoch =    20, avg_loss = 0.006664, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385,\n",
       "   epoch =    20, avg_loss = 0.006715, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385),\n",
       "  (epoch =    21, avg_loss = 0.006664, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385,\n",
       "   epoch =    21, avg_loss = 0.006705, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385),\n",
       "  (epoch =    22, avg_loss = 0.006663, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385,\n",
       "   epoch =    22, avg_loss = 0.006699, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385),\n",
       "  (epoch =    23, avg_loss = 0.006664, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385,\n",
       "   epoch =    23, avg_loss = 0.006698, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385),\n",
       "  (epoch =    24, avg_loss = 0.006663, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385,\n",
       "   epoch =    24, avg_loss = 0.006701, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385),\n",
       "  (epoch =    25, avg_loss = 0.006663, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385,\n",
       "   epoch =    25, avg_loss = 0.006710, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385),\n",
       "  (epoch =    26, avg_loss = 0.006663, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385,\n",
       "   epoch =    26, avg_loss = 0.006697, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385),\n",
       "  (epoch =    27, avg_loss = 0.006663, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385,\n",
       "   epoch =    27, avg_loss = 0.006694, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385),\n",
       "  (epoch =    28, avg_loss = 0.006661, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385,\n",
       "   epoch =    28, avg_loss = 0.006706, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385),\n",
       "  (epoch =    29, avg_loss = 0.006661, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385,\n",
       "   epoch =    29, avg_loss = 0.006720, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385),\n",
       "  (epoch =    30, avg_loss = 0.006661, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385,\n",
       "   epoch =    30, avg_loss = 0.006724, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385),\n",
       "  (epoch =    31, avg_loss = 0.006660, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385,\n",
       "   epoch =    31, avg_loss = 0.006742, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385),\n",
       "  (epoch =    32, avg_loss = 0.006665, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385,\n",
       "   epoch =    32, avg_loss = 0.006763, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385),\n",
       "  (epoch =    33, avg_loss = 0.006660, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385,\n",
       "   epoch =    33, avg_loss = 0.006749, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385),\n",
       "  (epoch =    34, avg_loss = 0.006659, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385,\n",
       "   epoch =    34, avg_loss = 0.006724, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385),\n",
       "  (epoch =    35, avg_loss = 0.006657, num_samples =   208, num_correct =    14, acc = 0.067308, bacc = 0.500000, score = -0.865385,\n",
       "   epoch =    35, avg_loss = 0.006703, num_samples =   208, num_correct =    38, acc = 0.182692, bacc = 0.561856, score = -0.634615),\n",
       "  (epoch =    36, avg_loss = 0.006656, num_samples =   208, num_correct =    46, acc = 0.221154, bacc = 0.582474, score = -0.557692,\n",
       "   epoch =    36, avg_loss = 0.006688, num_samples =   208, num_correct =    54, acc = 0.259615, bacc = 0.603093, score = -0.480769),\n",
       "  (epoch =    37, avg_loss = 0.006657, num_samples =   208, num_correct =    66, acc = 0.317308, bacc = 0.567747, score = -0.365385,\n",
       "   epoch =    37, avg_loss = 0.006669, num_samples =   208, num_correct =    90, acc = 0.432692, bacc = 0.497054, score = -0.134615),\n",
       "  (epoch =    38, avg_loss = 0.006657, num_samples =   208, num_correct =    84, acc = 0.403846, bacc = 0.514728, score = -0.192308,\n",
       "   epoch =    38, avg_loss = 0.006679, num_samples =   208, num_correct =    84, acc = 0.403846, bacc = 0.514728, score = -0.192308),\n",
       "  (epoch =    39, avg_loss = 0.006658, num_samples =   208, num_correct =    90, acc = 0.432692, bacc = 0.497054, score = -0.134615,\n",
       "   epoch =    39, avg_loss = 0.006640, num_samples =   208, num_correct =   106, acc = 0.509615, bacc = 0.538292, score = 0.019231),\n",
       "  (epoch =    40, avg_loss = 0.006652, num_samples =   208, num_correct =   122, acc = 0.586538, bacc = 0.579529, score = 0.173077,\n",
       "   epoch =    40, avg_loss = 0.006635, num_samples =   208, num_correct =   122, acc = 0.586538, bacc = 0.579529, score = 0.173077),\n",
       "  (epoch =    41, avg_loss = 0.006655, num_samples =   208, num_correct =    98, acc = 0.471154, bacc = 0.517673, score = -0.057692,\n",
       "   epoch =    41, avg_loss = 0.006637, num_samples =   208, num_correct =    90, acc = 0.432692, bacc = 0.497054, score = -0.134615),\n",
       "  (epoch =    42, avg_loss = 0.006646, num_samples =   208, num_correct =    98, acc = 0.471154, bacc = 0.517673, score = -0.057692,\n",
       "   epoch =    42, avg_loss = 0.006610, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =    43, avg_loss = 0.006645, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =    43, avg_loss = 0.006596, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =    44, avg_loss = 0.006644, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =    44, avg_loss = 0.006573, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =    45, avg_loss = 0.006642, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =    45, avg_loss = 0.006571, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =    46, avg_loss = 0.006636, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =    46, avg_loss = 0.006557, num_samples =   208, num_correct =   138, acc = 0.663462, bacc = 0.620766, score = 0.326923),\n",
       "  (epoch =    47, avg_loss = 0.006620, num_samples =   208, num_correct =   122, acc = 0.586538, bacc = 0.579529, score = 0.173077,\n",
       "   epoch =    47, avg_loss = 0.006579, num_samples =   208, num_correct =   106, acc = 0.509615, bacc = 0.538292, score = 0.019231),\n",
       "  (epoch =    48, avg_loss = 0.006621, num_samples =   208, num_correct =   106, acc = 0.509615, bacc = 0.538292, score = 0.019231,\n",
       "   epoch =    48, avg_loss = 0.006538, num_samples =   208, num_correct =   138, acc = 0.663462, bacc = 0.620766, score = 0.326923),\n",
       "  (epoch =    49, avg_loss = 0.006626, num_samples =   208, num_correct =   138, acc = 0.663462, bacc = 0.620766, score = 0.326923,\n",
       "   epoch =    49, avg_loss = 0.006533, num_samples =   208, num_correct =   130, acc = 0.625000, bacc = 0.600147, score = 0.250000),\n",
       "  (epoch =    50, avg_loss = 0.006611, num_samples =   208, num_correct =   106, acc = 0.509615, bacc = 0.538292, score = 0.019231,\n",
       "   epoch =    50, avg_loss = 0.006541, num_samples =   208, num_correct =   122, acc = 0.586538, bacc = 0.579529, score = 0.173077),\n",
       "  (epoch =    51, avg_loss = 0.006614, num_samples =   208, num_correct =   122, acc = 0.586538, bacc = 0.579529, score = 0.173077,\n",
       "   epoch =    51, avg_loss = 0.006528, num_samples =   208, num_correct =   122, acc = 0.586538, bacc = 0.579529, score = 0.173077),\n",
       "  (epoch =    52, avg_loss = 0.006603, num_samples =   208, num_correct =   122, acc = 0.586538, bacc = 0.579529, score = 0.173077,\n",
       "   epoch =    52, avg_loss = 0.006518, num_samples =   208, num_correct =   106, acc = 0.509615, bacc = 0.538292, score = 0.019231),\n",
       "  (epoch =    53, avg_loss = 0.006600, num_samples =   208, num_correct =   106, acc = 0.509615, bacc = 0.538292, score = 0.019231,\n",
       "   epoch =    53, avg_loss = 0.006513, num_samples =   208, num_correct =   106, acc = 0.509615, bacc = 0.538292, score = 0.019231),\n",
       "  (epoch =    54, avg_loss = 0.006582, num_samples =   208, num_correct =   114, acc = 0.548077, bacc = 0.558910, score = 0.096154,\n",
       "   epoch =    54, avg_loss = 0.006427, num_samples =   208, num_correct =   138, acc = 0.663462, bacc = 0.620766, score = 0.326923),\n",
       "  (epoch =    55, avg_loss = 0.006594, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =    55, avg_loss = 0.006354, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =    56, avg_loss = 0.006594, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =    56, avg_loss = 0.006331, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =    57, avg_loss = 0.006547, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =    57, avg_loss = 0.006429, num_samples =   208, num_correct =   122, acc = 0.586538, bacc = 0.579529, score = 0.173077),\n",
       "  (epoch =    58, avg_loss = 0.006555, num_samples =   208, num_correct =   122, acc = 0.586538, bacc = 0.579529, score = 0.173077,\n",
       "   epoch =    58, avg_loss = 0.006545, num_samples =   208, num_correct =    90, acc = 0.432692, bacc = 0.497054, score = -0.134615),\n",
       "  (epoch =    59, avg_loss = 0.006554, num_samples =   208, num_correct =    90, acc = 0.432692, bacc = 0.497054, score = -0.134615,\n",
       "   epoch =    59, avg_loss = 0.006567, num_samples =   208, num_correct =    90, acc = 0.432692, bacc = 0.497054, score = -0.134615),\n",
       "  (epoch =    60, avg_loss = 0.006547, num_samples =   208, num_correct =    90, acc = 0.432692, bacc = 0.497054, score = -0.134615,\n",
       "   epoch =    60, avg_loss = 0.006392, num_samples =   208, num_correct =   106, acc = 0.509615, bacc = 0.538292, score = 0.019231),\n",
       "  (epoch =    61, avg_loss = 0.006531, num_samples =   208, num_correct =   114, acc = 0.548077, bacc = 0.558910, score = 0.096154,\n",
       "   epoch =    61, avg_loss = 0.006250, num_samples =   208, num_correct =   138, acc = 0.663462, bacc = 0.620766, score = 0.326923),\n",
       "  (epoch =    62, avg_loss = 0.006534, num_samples =   208, num_correct =   130, acc = 0.625000, bacc = 0.600147, score = 0.250000,\n",
       "   epoch =    62, avg_loss = 0.006308, num_samples =   208, num_correct =   122, acc = 0.586538, bacc = 0.579529, score = 0.173077),\n",
       "  (epoch =    63, avg_loss = 0.006520, num_samples =   208, num_correct =   106, acc = 0.509615, bacc = 0.538292, score = 0.019231,\n",
       "   epoch =    63, avg_loss = 0.006387, num_samples =   208, num_correct =    90, acc = 0.432692, bacc = 0.497054, score = -0.134615),\n",
       "  (epoch =    64, avg_loss = 0.006535, num_samples =   208, num_correct =    90, acc = 0.432692, bacc = 0.497054, score = -0.134615,\n",
       "   epoch =    64, avg_loss = 0.006352, num_samples =   208, num_correct =    98, acc = 0.471154, bacc = 0.517673, score = -0.057692),\n",
       "  (epoch =    65, avg_loss = 0.006513, num_samples =   208, num_correct =   106, acc = 0.509615, bacc = 0.538292, score = 0.019231,\n",
       "   epoch =    65, avg_loss = 0.006289, num_samples =   208, num_correct =   106, acc = 0.509615, bacc = 0.538292, score = 0.019231),\n",
       "  (epoch =    66, avg_loss = 0.006509, num_samples =   208, num_correct =   106, acc = 0.509615, bacc = 0.538292, score = 0.019231,\n",
       "   epoch =    66, avg_loss = 0.006316, num_samples =   208, num_correct =    98, acc = 0.471154, bacc = 0.517673, score = -0.057692),\n",
       "  (epoch =    67, avg_loss = 0.006411, num_samples =   208, num_correct =    98, acc = 0.471154, bacc = 0.517673, score = -0.057692,\n",
       "   epoch =    67, avg_loss = 0.006215, num_samples =   208, num_correct =   114, acc = 0.548077, bacc = 0.558910, score = 0.096154),\n",
       "  (epoch =    68, avg_loss = 0.006492, num_samples =   208, num_correct =   122, acc = 0.586538, bacc = 0.579529, score = 0.173077,\n",
       "   epoch =    68, avg_loss = 0.006041, num_samples =   208, num_correct =   138, acc = 0.663462, bacc = 0.620766, score = 0.326923),\n",
       "  (epoch =    69, avg_loss = 0.006348, num_samples =   208, num_correct =   138, acc = 0.663462, bacc = 0.620766, score = 0.326923,\n",
       "   epoch =    69, avg_loss = 0.006113, num_samples =   208, num_correct =   122, acc = 0.586538, bacc = 0.579529, score = 0.173077),\n",
       "  (epoch =    70, avg_loss = 0.006372, num_samples =   208, num_correct =   114, acc = 0.548077, bacc = 0.558910, score = 0.096154,\n",
       "   epoch =    70, avg_loss = 0.006080, num_samples =   208, num_correct =   122, acc = 0.586538, bacc = 0.579529, score = 0.173077),\n",
       "  (epoch =    71, avg_loss = 0.006373, num_samples =   208, num_correct =   122, acc = 0.586538, bacc = 0.579529, score = 0.173077,\n",
       "   epoch =    71, avg_loss = 0.005886, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =    72, avg_loss = 0.006364, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =    72, avg_loss = 0.005765, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =    73, avg_loss = 0.006397, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =    73, avg_loss = 0.005861, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =    74, avg_loss = 0.006381, num_samples =   208, num_correct =   138, acc = 0.663462, bacc = 0.620766, score = 0.326923,\n",
       "   epoch =    74, avg_loss = 0.006084, num_samples =   208, num_correct =   114, acc = 0.548077, bacc = 0.558910, score = 0.096154),\n",
       "  (epoch =    75, avg_loss = 0.006427, num_samples =   208, num_correct =   106, acc = 0.509615, bacc = 0.538292, score = 0.019231,\n",
       "   epoch =    75, avg_loss = 0.006197, num_samples =   208, num_correct =    98, acc = 0.471154, bacc = 0.517673, score = -0.057692),\n",
       "  (epoch =    76, avg_loss = 0.006413, num_samples =   208, num_correct =    98, acc = 0.471154, bacc = 0.517673, score = -0.057692,\n",
       "   epoch =    76, avg_loss = 0.006102, num_samples =   208, num_correct =   114, acc = 0.548077, bacc = 0.558910, score = 0.096154),\n",
       "  (epoch =    77, avg_loss = 0.006404, num_samples =   208, num_correct =   114, acc = 0.548077, bacc = 0.558910, score = 0.096154,\n",
       "   epoch =    77, avg_loss = 0.006131, num_samples =   208, num_correct =    98, acc = 0.471154, bacc = 0.517673, score = -0.057692),\n",
       "  (epoch =    78, avg_loss = 0.006269, num_samples =   208, num_correct =    90, acc = 0.432692, bacc = 0.497054, score = -0.134615,\n",
       "   epoch =    78, avg_loss = 0.006292, num_samples =   208, num_correct =    90, acc = 0.432692, bacc = 0.497054, score = -0.134615),\n",
       "  (epoch =    79, avg_loss = 0.006386, num_samples =   208, num_correct =    90, acc = 0.432692, bacc = 0.497054, score = -0.134615,\n",
       "   epoch =    79, avg_loss = 0.005993, num_samples =   208, num_correct =   114, acc = 0.548077, bacc = 0.558910, score = 0.096154),\n",
       "  (epoch =    80, avg_loss = 0.006429, num_samples =   208, num_correct =   130, acc = 0.625000, bacc = 0.600147, score = 0.250000,\n",
       "   epoch =    80, avg_loss = 0.005705, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =    81, avg_loss = 0.006411, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =    81, avg_loss = 0.005651, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =    82, avg_loss = 0.006388, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =    82, avg_loss = 0.005791, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =    83, avg_loss = 0.006368, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =    83, avg_loss = 0.005964, num_samples =   208, num_correct =   130, acc = 0.625000, bacc = 0.600147, score = 0.250000),\n",
       "  (epoch =    84, avg_loss = 0.006269, num_samples =   208, num_correct =   122, acc = 0.586538, bacc = 0.579529, score = 0.173077,\n",
       "   epoch =    84, avg_loss = 0.006106, num_samples =   208, num_correct =   106, acc = 0.509615, bacc = 0.538292, score = 0.019231),\n",
       "  (epoch =    85, avg_loss = 0.006343, num_samples =   208, num_correct =   106, acc = 0.509615, bacc = 0.538292, score = 0.019231,\n",
       "   epoch =    85, avg_loss = 0.006097, num_samples =   208, num_correct =   114, acc = 0.548077, bacc = 0.558910, score = 0.096154),\n",
       "  (epoch =    86, avg_loss = 0.006422, num_samples =   208, num_correct =   114, acc = 0.548077, bacc = 0.558910, score = 0.096154,\n",
       "   epoch =    86, avg_loss = 0.005960, num_samples =   208, num_correct =   130, acc = 0.625000, bacc = 0.600147, score = 0.250000),\n",
       "  (epoch =    87, avg_loss = 0.006319, num_samples =   208, num_correct =   130, acc = 0.625000, bacc = 0.600147, score = 0.250000,\n",
       "   epoch =    87, avg_loss = 0.005871, num_samples =   208, num_correct =   138, acc = 0.663462, bacc = 0.620766, score = 0.326923),\n",
       "  (epoch =    88, avg_loss = 0.006314, num_samples =   208, num_correct =   130, acc = 0.625000, bacc = 0.600147, score = 0.250000,\n",
       "   epoch =    88, avg_loss = 0.005812, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =    89, avg_loss = 0.006430, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =    89, avg_loss = 0.005752, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =    90, avg_loss = 0.006368, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =    90, avg_loss = 0.005930, num_samples =   208, num_correct =   130, acc = 0.625000, bacc = 0.600147, score = 0.250000),\n",
       "  (epoch =    91, avg_loss = 0.006394, num_samples =   208, num_correct =   114, acc = 0.548077, bacc = 0.558910, score = 0.096154,\n",
       "   epoch =    91, avg_loss = 0.006074, num_samples =   208, num_correct =    98, acc = 0.471154, bacc = 0.517673, score = -0.057692),\n",
       "  (epoch =    92, avg_loss = 0.006350, num_samples =   208, num_correct =   106, acc = 0.509615, bacc = 0.538292, score = 0.019231,\n",
       "   epoch =    92, avg_loss = 0.006079, num_samples =   208, num_correct =    98, acc = 0.471154, bacc = 0.517673, score = -0.057692),\n",
       "  (epoch =    93, avg_loss = 0.006379, num_samples =   208, num_correct =    98, acc = 0.471154, bacc = 0.517673, score = -0.057692,\n",
       "   epoch =    93, avg_loss = 0.006008, num_samples =   208, num_correct =   114, acc = 0.548077, bacc = 0.558910, score = 0.096154),\n",
       "  (epoch =    94, avg_loss = 0.006365, num_samples =   208, num_correct =   114, acc = 0.548077, bacc = 0.558910, score = 0.096154,\n",
       "   epoch =    94, avg_loss = 0.005988, num_samples =   208, num_correct =   114, acc = 0.548077, bacc = 0.558910, score = 0.096154),\n",
       "  (epoch =    95, avg_loss = 0.006266, num_samples =   208, num_correct =   114, acc = 0.548077, bacc = 0.558910, score = 0.096154,\n",
       "   epoch =    95, avg_loss = 0.006017, num_samples =   208, num_correct =   114, acc = 0.548077, bacc = 0.558910, score = 0.096154),\n",
       "  (epoch =    96, avg_loss = 0.006333, num_samples =   208, num_correct =   114, acc = 0.548077, bacc = 0.558910, score = 0.096154,\n",
       "   epoch =    96, avg_loss = 0.005996, num_samples =   208, num_correct =   114, acc = 0.548077, bacc = 0.558910, score = 0.096154),\n",
       "  (epoch =    97, avg_loss = 0.006164, num_samples =   208, num_correct =   106, acc = 0.509615, bacc = 0.538292, score = 0.019231,\n",
       "   epoch =    97, avg_loss = 0.006060, num_samples =   208, num_correct =    90, acc = 0.432692, bacc = 0.497054, score = -0.134615),\n",
       "  (epoch =    98, avg_loss = 0.006327, num_samples =   208, num_correct =    98, acc = 0.471154, bacc = 0.517673, score = -0.057692,\n",
       "   epoch =    98, avg_loss = 0.005975, num_samples =   208, num_correct =   122, acc = 0.586538, bacc = 0.579529, score = 0.173077),\n",
       "  (epoch =    99, avg_loss = 0.006384, num_samples =   208, num_correct =   138, acc = 0.663462, bacc = 0.620766, score = 0.326923,\n",
       "   epoch =    99, avg_loss = 0.005996, num_samples =   208, num_correct =   122, acc = 0.586538, bacc = 0.579529, score = 0.173077),\n",
       "  (epoch =   100, avg_loss = 0.006225, num_samples =   208, num_correct =    98, acc = 0.471154, bacc = 0.517673, score = -0.057692,\n",
       "   epoch =   100, avg_loss = 0.006037, num_samples =   208, num_correct =   106, acc = 0.509615, bacc = 0.538292, score = 0.019231),\n",
       "  (epoch =   101, avg_loss = 0.006389, num_samples =   208, num_correct =   130, acc = 0.625000, bacc = 0.600147, score = 0.250000,\n",
       "   epoch =   101, avg_loss = 0.005844, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   102, avg_loss = 0.006313, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   102, avg_loss = 0.005965, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   103, avg_loss = 0.006341, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   103, avg_loss = 0.005940, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   104, avg_loss = 0.006416, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   104, avg_loss = 0.005880, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   105, avg_loss = 0.006384, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   105, avg_loss = 0.006051, num_samples =   208, num_correct =   138, acc = 0.663462, bacc = 0.620766, score = 0.326923),\n",
       "  (epoch =   106, avg_loss = 0.006308, num_samples =   208, num_correct =   138, acc = 0.663462, bacc = 0.620766, score = 0.326923,\n",
       "   epoch =   106, avg_loss = 0.006025, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   107, avg_loss = 0.006267, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   107, avg_loss = 0.005925, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   108, avg_loss = 0.006329, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   108, avg_loss = 0.005759, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   109, avg_loss = 0.006398, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   109, avg_loss = 0.005910, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   110, avg_loss = 0.006364, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   110, avg_loss = 0.006190, num_samples =   208, num_correct =    90, acc = 0.432692, bacc = 0.497054, score = -0.134615),\n",
       "  (epoch =   111, avg_loss = 0.006362, num_samples =   208, num_correct =    90, acc = 0.432692, bacc = 0.497054, score = -0.134615,\n",
       "   epoch =   111, avg_loss = 0.006142, num_samples =   208, num_correct =    90, acc = 0.432692, bacc = 0.497054, score = -0.134615),\n",
       "  (epoch =   112, avg_loss = 0.006233, num_samples =   208, num_correct =   114, acc = 0.548077, bacc = 0.558910, score = 0.096154,\n",
       "   epoch =   112, avg_loss = 0.005808, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   113, avg_loss = 0.006312, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   113, avg_loss = 0.005662, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   114, avg_loss = 0.006281, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   114, avg_loss = 0.005947, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   115, avg_loss = 0.006281, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   115, avg_loss = 0.005992, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   116, avg_loss = 0.006330, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   116, avg_loss = 0.005896, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   117, avg_loss = 0.006240, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   117, avg_loss = 0.005758, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   118, avg_loss = 0.006249, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   118, avg_loss = 0.005892, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   119, avg_loss = 0.006253, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   119, avg_loss = 0.006081, num_samples =   208, num_correct =   130, acc = 0.625000, bacc = 0.600147, score = 0.250000),\n",
       "  (epoch =   120, avg_loss = 0.006238, num_samples =   208, num_correct =   138, acc = 0.663462, bacc = 0.620766, score = 0.326923,\n",
       "   epoch =   120, avg_loss = 0.005840, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   121, avg_loss = 0.006319, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   121, avg_loss = 0.005758, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   122, avg_loss = 0.006223, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   122, avg_loss = 0.006016, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   123, avg_loss = 0.006243, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   123, avg_loss = 0.006091, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   124, avg_loss = 0.006285, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   124, avg_loss = 0.005939, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   125, avg_loss = 0.006076, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   125, avg_loss = 0.005687, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   126, avg_loss = 0.006261, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   126, avg_loss = 0.005798, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   127, avg_loss = 0.006177, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   127, avg_loss = 0.006039, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   128, avg_loss = 0.006241, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   128, avg_loss = 0.005905, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   129, avg_loss = 0.006117, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   129, avg_loss = 0.005520, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   130, avg_loss = 0.006289, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   130, avg_loss = 0.005532, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   131, avg_loss = 0.006169, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   131, avg_loss = 0.005996, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   132, avg_loss = 0.006206, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   132, avg_loss = 0.006085, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   133, avg_loss = 0.006225, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   133, avg_loss = 0.005837, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   134, avg_loss = 0.006020, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   134, avg_loss = 0.005579, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   135, avg_loss = 0.006201, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   135, avg_loss = 0.005293, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   136, avg_loss = 0.006269, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   136, avg_loss = 0.005633, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   137, avg_loss = 0.005932, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   137, avg_loss = 0.006025, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   138, avg_loss = 0.006171, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   138, avg_loss = 0.006003, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   139, avg_loss = 0.006091, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   139, avg_loss = 0.005781, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   140, avg_loss = 0.005697, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   140, avg_loss = 0.005352, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   141, avg_loss = 0.005994, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   141, avg_loss = 0.005311, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   142, avg_loss = 0.006128, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   142, avg_loss = 0.005550, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   143, avg_loss = 0.006117, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   143, avg_loss = 0.005768, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   144, avg_loss = 0.006180, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   144, avg_loss = 0.005640, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   145, avg_loss = 0.006111, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   145, avg_loss = 0.005334, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   146, avg_loss = 0.005975, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   146, avg_loss = 0.005235, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   147, avg_loss = 0.006096, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   147, avg_loss = 0.005537, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   148, avg_loss = 0.005912, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   148, avg_loss = 0.005668, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   149, avg_loss = 0.006030, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   149, avg_loss = 0.005557, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   150, avg_loss = 0.005754, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   150, avg_loss = 0.005344, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   151, avg_loss = 0.005902, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   151, avg_loss = 0.005608, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   152, avg_loss = 0.005993, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   152, avg_loss = 0.005766, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   153, avg_loss = 0.006039, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   153, avg_loss = 0.005493, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   154, avg_loss = 0.005854, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   154, avg_loss = 0.005160, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   155, avg_loss = 0.005887, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   155, avg_loss = 0.005407, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   156, avg_loss = 0.005938, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   156, avg_loss = 0.005600, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   157, avg_loss = 0.005977, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   157, avg_loss = 0.005597, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   158, avg_loss = 0.005973, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   158, avg_loss = 0.005478, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   159, avg_loss = 0.005862, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   159, avg_loss = 0.005562, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   160, avg_loss = 0.005909, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   160, avg_loss = 0.005687, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   161, avg_loss = 0.005923, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   161, avg_loss = 0.005518, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   162, avg_loss = 0.005807, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   162, avg_loss = 0.005386, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   163, avg_loss = 0.005829, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   163, avg_loss = 0.005464, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   164, avg_loss = 0.005841, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   164, avg_loss = 0.005509, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   165, avg_loss = 0.005541, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   165, avg_loss = 0.005446, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   166, avg_loss = 0.005787, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   166, avg_loss = 0.005669, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   167, avg_loss = 0.005720, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   167, avg_loss = 0.005453, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   168, avg_loss = 0.005687, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   168, avg_loss = 0.005311, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   169, avg_loss = 0.005613, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   169, avg_loss = 0.005396, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   170, avg_loss = 0.005654, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846,\n",
       "   epoch =   170, avg_loss = 0.005384, num_samples =   208, num_correct =   146, acc = 0.701923, bacc = 0.641384, score = 0.403846),\n",
       "  (epoch =   171, avg_loss = 0.005592, num_samples =   208, num_correct =   128, acc = 0.615385, bacc = 0.694404, score = 0.230769,\n",
       "   epoch =   171, avg_loss = 0.005351, num_samples =   208, num_correct =   134, acc = 0.644231, bacc = 0.676730, score = 0.288462),\n",
       "  (epoch =   172, avg_loss = 0.005454, num_samples =   208, num_correct =   128, acc = 0.615385, bacc = 0.694404, score = 0.230769,\n",
       "   epoch =   172, avg_loss = 0.005561, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692),\n",
       "  (epoch =   173, avg_loss = 0.005419, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692,\n",
       "   epoch =   173, avg_loss = 0.005356, num_samples =   208, num_correct =   122, acc = 0.586538, bacc = 0.712077, score = 0.173077),\n",
       "  (epoch =   174, avg_loss = 0.005473, num_samples =   208, num_correct =   116, acc = 0.557692, bacc = 0.729750, score = 0.115385,\n",
       "   epoch =   174, avg_loss = 0.005403, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692),\n",
       "  (epoch =   175, avg_loss = 0.005490, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692,\n",
       "   epoch =   175, avg_loss = 0.005228, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692),\n",
       "  (epoch =   176, avg_loss = 0.005401, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692,\n",
       "   epoch =   176, avg_loss = 0.005134, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692),\n",
       "  (epoch =   177, avg_loss = 0.005432, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692,\n",
       "   epoch =   177, avg_loss = 0.005400, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692),\n",
       "  (epoch =   178, avg_loss = 0.005357, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692,\n",
       "   epoch =   178, avg_loss = 0.005265, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692),\n",
       "  (epoch =   179, avg_loss = 0.005379, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692,\n",
       "   epoch =   179, avg_loss = 0.005126, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692),\n",
       "  (epoch =   180, avg_loss = 0.005316, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692,\n",
       "   epoch =   180, avg_loss = 0.005323, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692),\n",
       "  (epoch =   181, avg_loss = 0.005251, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692,\n",
       "   epoch =   181, avg_loss = 0.005419, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692),\n",
       "  (epoch =   182, avg_loss = 0.005117, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692,\n",
       "   epoch =   182, avg_loss = 0.005359, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692),\n",
       "  (epoch =   183, avg_loss = 0.005080, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692,\n",
       "   epoch =   183, avg_loss = 0.005432, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692),\n",
       "  (epoch =   184, avg_loss = 0.005130, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692,\n",
       "   epoch =   184, avg_loss = 0.005269, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692),\n",
       "  (epoch =   185, avg_loss = 0.005011, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692,\n",
       "   epoch =   185, avg_loss = 0.005196, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692),\n",
       "  (epoch =   186, avg_loss = 0.005039, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692,\n",
       "   epoch =   186, avg_loss = 0.005125, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692),\n",
       "  (epoch =   187, avg_loss = 0.004902, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692,\n",
       "   epoch =   187, avg_loss = 0.005170, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692),\n",
       "  (epoch =   188, avg_loss = 0.004944, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692,\n",
       "   epoch =   188, avg_loss = 0.005275, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692),\n",
       "  (epoch =   189, avg_loss = 0.004909, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692,\n",
       "   epoch =   189, avg_loss = 0.005384, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692),\n",
       "  (epoch =   190, avg_loss = 0.004673, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692,\n",
       "   epoch =   190, avg_loss = 0.005310, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692),\n",
       "  (epoch =   191, avg_loss = 0.004845, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692,\n",
       "   epoch =   191, avg_loss = 0.005140, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692),\n",
       "  (epoch =   192, avg_loss = 0.004375, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692,\n",
       "   epoch =   192, avg_loss = 0.004982, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692),\n",
       "  (epoch =   193, avg_loss = 0.004781, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692,\n",
       "   epoch =   193, avg_loss = 0.005184, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692),\n",
       "  (epoch =   194, avg_loss = 0.004759, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692,\n",
       "   epoch =   194, avg_loss = 0.005085, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692),\n",
       "  (epoch =   195, avg_loss = 0.004024, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692,\n",
       "   epoch =   195, avg_loss = 0.004949, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692),\n",
       "  (epoch =   196, avg_loss = 0.004800, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692,\n",
       "   epoch =   196, avg_loss = 0.005017, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692),\n",
       "  (epoch =   197, avg_loss = 0.004782, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692,\n",
       "   epoch =   197, avg_loss = 0.005492, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692),\n",
       "  (epoch =   198, avg_loss = 0.004659, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692,\n",
       "   epoch =   198, avg_loss = 0.005804, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692),\n",
       "  (epoch =   199, avg_loss = 0.004756, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692,\n",
       "   epoch =   199, avg_loss = 0.004950, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692),\n",
       "  (epoch =   200, avg_loss = 0.004490, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692,\n",
       "   epoch =   200, avg_loss = 0.004398, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692),\n",
       "  (epoch =   201, avg_loss = 0.004661, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692,\n",
       "   epoch =   201, avg_loss = 0.005169, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692),\n",
       "  (epoch =   202, avg_loss = 0.004717, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692,\n",
       "   epoch =   202, avg_loss = 0.005820, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692),\n",
       "  (epoch =   203, avg_loss = 0.004685, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692,\n",
       "   epoch =   203, avg_loss = 0.005346, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692),\n",
       "  (epoch =   204, avg_loss = 0.004674, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692,\n",
       "   epoch =   204, avg_loss = 0.004991, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692),\n",
       "  (epoch =   205, avg_loss = 0.004432, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692,\n",
       "   epoch =   205, avg_loss = 0.004725, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692),\n",
       "  (epoch =   206, avg_loss = 0.004695, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692,\n",
       "   epoch =   206, avg_loss = 0.005274, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692),\n",
       "  (epoch =   207, avg_loss = 0.004577, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692,\n",
       "   epoch =   207, avg_loss = 0.005488, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692),\n",
       "  (epoch =   208, avg_loss = 0.004582, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692,\n",
       "   epoch =   208, avg_loss = 0.004904, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692),\n",
       "  (epoch =   209, avg_loss = 0.004506, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692,\n",
       "   epoch =   209, avg_loss = 0.004334, num_samples =   208, num_correct =   140, acc = 0.673077, bacc = 0.824742, score = 0.346154),\n",
       "  (epoch =   210, avg_loss = 0.004456, num_samples =   208, num_correct =   135, acc = 0.649038, bacc = 0.811856, score = 0.298077,\n",
       "   epoch =   210, avg_loss = 0.004502, num_samples =   208, num_correct =   110, acc = 0.528846, bacc = 0.747423, score = 0.057692),\n",
       "  (epoch =   211, avg_loss = 0.004101, num_samples =   208, num_correct =   117, acc = 0.562500, bacc = 0.765464, score = 0.125000,\n",
       "   epoch =   211, avg_loss = 0.004621, num_samples =   208, num_correct =   117, acc = 0.562500, bacc = 0.765464, score = 0.125000),\n",
       "  (epoch =   212, avg_loss = 0.003636, num_samples =   208, num_correct =   126, acc = 0.605769, bacc = 0.788660, score = 0.211538,\n",
       "   epoch =   212, avg_loss = 0.004135, num_samples =   208, num_correct =   140, acc = 0.673077, bacc = 0.824742, score = 0.346154),\n",
       "  (epoch =   213, avg_loss = 0.003333, num_samples =   208, num_correct =   147, acc = 0.706731, bacc = 0.842784, score = 0.413462,\n",
       "   epoch =   213, avg_loss = 0.003158, num_samples =   208, num_correct =   182, acc = 0.875000, bacc = 0.932990, score = 0.750000),\n",
       "  (epoch =   214, avg_loss = 0.002583, num_samples =   208, num_correct =   189, acc = 0.908654, bacc = 0.951031, score = 0.817308,\n",
       "   epoch =   214, avg_loss = 0.002340, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   215, avg_loss = 0.001889, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   215, avg_loss = 0.002071, num_samples =   208, num_correct =   193, acc = 0.927885, bacc = 0.961340, score = 0.855769),\n",
       "  (epoch =   216, avg_loss = 0.001346, num_samples =   208, num_correct =   193, acc = 0.927885, bacc = 0.961340, score = 0.855769,\n",
       "   epoch =   216, avg_loss = 0.002022, num_samples =   208, num_correct =   193, acc = 0.927885, bacc = 0.961340, score = 0.855769),\n",
       "  (epoch =   217, avg_loss = 0.001295, num_samples =   208, num_correct =   193, acc = 0.927885, bacc = 0.961340, score = 0.855769,\n",
       "   epoch =   217, avg_loss = 0.001468, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   218, avg_loss = 0.001092, num_samples =   208, num_correct =   193, acc = 0.927885, bacc = 0.961340, score = 0.855769,\n",
       "   epoch =   218, avg_loss = 0.001789, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.963918, score = 0.865385),\n",
       "  (epoch =   219, avg_loss = 0.001005, num_samples =   208, num_correct =   194, acc = 0.932692, bacc = 0.963918, score = 0.865385,\n",
       "   epoch =   219, avg_loss = 0.001560, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   220, avg_loss = 0.000854, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   220, avg_loss = 0.001449, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   221, avg_loss = 0.000925, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   221, avg_loss = 0.001364, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   222, avg_loss = 0.000953, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   222, avg_loss = 0.001318, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   223, avg_loss = 0.000938, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   223, avg_loss = 0.001334, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   224, avg_loss = 0.001008, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   224, avg_loss = 0.001341, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   225, avg_loss = 0.000692, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   225, avg_loss = 0.001359, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   226, avg_loss = 0.000959, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   226, avg_loss = 0.001630, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   227, avg_loss = 0.000903, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   227, avg_loss = 0.001462, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   228, avg_loss = 0.000848, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   228, avg_loss = 0.001636, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   229, avg_loss = 0.000803, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   229, avg_loss = 0.001208, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   230, avg_loss = 0.000967, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   230, avg_loss = 0.001653, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   231, avg_loss = 0.000917, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   231, avg_loss = 0.001542, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   232, avg_loss = 0.000821, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   232, avg_loss = 0.001123, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   233, avg_loss = 0.001097, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   233, avg_loss = 0.001669, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   234, avg_loss = 0.000831, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   234, avg_loss = 0.001100, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   235, avg_loss = 0.000854, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   235, avg_loss = 0.001699, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   236, avg_loss = 0.000642, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   236, avg_loss = 0.001537, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   237, avg_loss = 0.001044, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   237, avg_loss = 0.001657, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   238, avg_loss = 0.000958, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   238, avg_loss = 0.001526, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   239, avg_loss = 0.000884, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   239, avg_loss = 0.001122, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   240, avg_loss = 0.000972, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   240, avg_loss = 0.001605, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   241, avg_loss = 0.001126, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   241, avg_loss = 0.001271, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   242, avg_loss = 0.000732, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   242, avg_loss = 0.001602, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   243, avg_loss = 0.000919, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   243, avg_loss = 0.001666, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   244, avg_loss = 0.000900, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   244, avg_loss = 0.001584, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   245, avg_loss = 0.000970, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   245, avg_loss = 0.001426, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   246, avg_loss = 0.000798, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   246, avg_loss = 0.001307, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   247, avg_loss = 0.000898, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   247, avg_loss = 0.001287, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   248, avg_loss = 0.000802, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   248, avg_loss = 0.001410, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   249, avg_loss = 0.000882, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   249, avg_loss = 0.001423, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   250, avg_loss = 0.000993, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   250, avg_loss = 0.001463, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   251, avg_loss = 0.000881, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   251, avg_loss = 0.001536, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   252, avg_loss = 0.000818, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   252, avg_loss = 0.001415, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   253, avg_loss = 0.000910, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   253, avg_loss = 0.001471, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   254, avg_loss = 0.000891, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   254, avg_loss = 0.001513, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   255, avg_loss = 0.000814, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   255, avg_loss = 0.001560, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   256, avg_loss = 0.000875, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   256, avg_loss = 0.001383, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   257, avg_loss = 0.000871, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   257, avg_loss = 0.001280, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   258, avg_loss = 0.000918, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   258, avg_loss = 0.001219, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   259, avg_loss = 0.000895, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   259, avg_loss = 0.001598, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   260, avg_loss = 0.000713, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   260, avg_loss = 0.001715, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   261, avg_loss = 0.000802, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   261, avg_loss = 0.001267, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   262, avg_loss = 0.000875, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   262, avg_loss = 0.001486, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   263, avg_loss = 0.000873, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   263, avg_loss = 0.001463, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   264, avg_loss = 0.000887, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   264, avg_loss = 0.001322, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   265, avg_loss = 0.000849, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   265, avg_loss = 0.001168, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   266, avg_loss = 0.000874, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   266, avg_loss = 0.001404, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   267, avg_loss = 0.000771, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   267, avg_loss = 0.001467, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   268, avg_loss = 0.000913, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   268, avg_loss = 0.001473, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   269, avg_loss = 0.000964, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   269, avg_loss = 0.001612, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   270, avg_loss = 0.000826, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   270, avg_loss = 0.001522, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   271, avg_loss = 0.000785, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   271, avg_loss = 0.000856, num_samples =   208, num_correct =   198, acc = 0.951923, bacc = 0.974227, score = 0.903846),\n",
       "  (epoch =   272, avg_loss = 0.000915, num_samples =   208, num_correct =   197, acc = 0.947115, bacc = 0.971649, score = 0.894231,\n",
       "   epoch =   272, avg_loss = 0.001520, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   273, avg_loss = 0.001057, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   273, avg_loss = 0.001600, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   274, avg_loss = 0.001019, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   274, avg_loss = 0.001851, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615),\n",
       "  (epoch =   275, avg_loss = 0.000985, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "   epoch =   275, avg_loss = 0.001766, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615)],\n",
       " AttentionClassifier(\n",
       "   (in_fnn): FNN(\n",
       "     (layers): Sequential(\n",
       "       (0): Dropout(p=0.45, inplace=False)\n",
       "       (1): Linear(in_features=1, out_features=128, bias=True)\n",
       "       (2): LeakyReLU(negative_slope=0.01)\n",
       "       (3): Dropout(p=0.45, inplace=False)\n",
       "       (4): Linear(in_features=128, out_features=64, bias=True)\n",
       "       (5): LeakyReLU(negative_slope=0.01)\n",
       "       (6): Dropout(p=0.45, inplace=False)\n",
       "       (7): Linear(in_features=64, out_features=64, bias=True)\n",
       "       (8): LeakyReLU(negative_slope=0.01)\n",
       "       (9): Dropout(p=0.45, inplace=False)\n",
       "       (10): Linear(in_features=64, out_features=64, bias=True)\n",
       "     )\n",
       "   )\n",
       "   (positional_encoder): PositionalEncoding()\n",
       "   (attention_stack): Sequential(\n",
       "     (0): MultiheadSelfAttention(\n",
       "       (multihead_attention): MultiheadAttention(\n",
       "         (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "       )\n",
       "     )\n",
       "     (1): LeakyReLU(negative_slope=0.01)\n",
       "     (2): MultiheadSelfAttention(\n",
       "       (multihead_attention): MultiheadAttention(\n",
       "         (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (out_fnn): FNN(\n",
       "     (layers): Sequential(\n",
       "       (0): Dropout(p=0.45, inplace=False)\n",
       "       (1): Linear(in_features=64, out_features=32, bias=True)\n",
       "       (2): LeakyReLU(negative_slope=0.01)\n",
       "       (3): Dropout(p=0.45, inplace=False)\n",
       "       (4): Linear(in_features=32, out_features=16, bias=True)\n",
       "       (5): LeakyReLU(negative_slope=0.01)\n",
       "       (6): Dropout(p=0.45, inplace=False)\n",
       "       (7): Linear(in_features=16, out_features=2, bias=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " (epoch =   271, avg_loss = 0.000785, num_samples =   208, num_correct =   196, acc = 0.942308, bacc = 0.969072, score = 0.884615,\n",
       "  epoch =   271, avg_loss = 0.000856, num_samples =   208, num_correct =   198, acc = 0.951923, bacc = 0.974227, score = 0.903846))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac = AttentionClassifier(ac_hyper_parameters, batch_first=True)\n",
    "    \n",
    "train_model(\n",
    "    ac,\n",
    "    training_hyper_parameters,\n",
    "    ds,\n",
    "    ds,\n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e5c31b65-b47e-4fbe-868f-f380c3de327c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_for_sequence(seq: list[int]):\n",
    "    return torch.argmax(ac.forward(torch.Tensor([[[float(e)] for e in seq]]).to(device)), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e470036e-5ad4-4d30-9aa4-992d1845f2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "predict_for_sequence([1, 0, 0, 0, 0, 0, 0, 0]) = tensor([[1, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "predict_for_sequence([0, 0, 0, 1, 0, 0, 0, 0]) = tensor([[0, 0, 0, 1, 0, 0, 0, 0]], device='cuda:0')\n",
      "predict_for_sequence([0, 0, 0, 0, 0, 0, 0, 1]) = tensor([[0, 0, 0, 0, 0, 0, 0, 1]], device='cuda:0')\n",
      "\n",
      "predict_for_sequence([ 1, 1, 0, 0, 0, 0,0, 0]) = tensor([[0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "predict_for_sequence([0, 0, 0, 0, 1, 1, 0, 0]) = tensor([[0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "predict_for_sequence([0, 0, 0, 0, 0, 0, 1, 1]) = tensor([[0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "\n",
      "predict_for_sequence([ 1, 1, 1, 0, 0, 0,0, 0]) = tensor([[1, 1, 1, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "predict_for_sequence([0, 0, 0, 1, 1, 1, 0, 0]) = tensor([[0, 0, 0, 1, 1, 1, 0, 0]], device='cuda:0')\n",
      "predict_for_sequence([0, 0, 0, 0, 0, 1, 1, 1]) = tensor([[0, 0, 0, 0, 0, 1, 1, 1]], device='cuda:0')\n",
      "\n",
      "predict_for_sequence([1, 1, 1, 1, 0, 0, 0, 0]) = tensor([[0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "predict_for_sequence([0, 0, 1, 1, 1, 1, 0, 0]) = tensor([[0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "predict_for_sequence([0, 0, 0, 0, 1, 1, 1, 1]) = tensor([[0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "\n",
      "\n",
      "Test\n",
      "predict_for_sequence([0, 0, 0, 1, 0, 1, 0, 1]) = tensor([[0, 0, 0, 1, 0, 1, 0, 1]], device='cuda:0')\n",
      "predict_for_sequence([1, 0, 0, 0, 0, 1, 0, 1]) = tensor([[1, 0, 0, 0, 0, 1, 0, 1]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print('Train')\n",
    "print(f'{predict_for_sequence([1, 0, 0, 0, 0, 0, 0, 0]) = }')\n",
    "print(f'{predict_for_sequence([0, 0, 0, 1, 0, 0, 0, 0]) = }')\n",
    "print(f'{predict_for_sequence([0, 0, 0, 0, 0, 0, 0, 1]) = }')\n",
    "print()\n",
    "print(f'{predict_for_sequence([ 1, 1, 0, 0, 0, 0,0, 0]) = }')\n",
    "print(f'{predict_for_sequence([0, 0, 0, 0, 1, 1, 0, 0]) = }')\n",
    "print(f'{predict_for_sequence([0, 0, 0, 0, 0, 0, 1, 1]) = }')\n",
    "print()\n",
    "print(f'{predict_for_sequence([ 1, 1, 1, 0, 0, 0,0, 0]) = }')\n",
    "print(f'{predict_for_sequence([0, 0, 0, 1, 1, 1, 0, 0]) = }')\n",
    "print(f'{predict_for_sequence([0, 0, 0, 0, 0, 1, 1, 1]) = }')\n",
    "print()\n",
    "print(f'{predict_for_sequence([1, 1, 1, 1, 0, 0, 0, 0]) = }')\n",
    "print(f'{predict_for_sequence([0, 0, 1, 1, 1, 1, 0, 0]) = }')\n",
    "print(f'{predict_for_sequence([0, 0, 0, 0, 1, 1, 1, 1]) = }')\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Test')\n",
    "\n",
    "print(f'{predict_for_sequence([0, 0, 0, 1, 0, 1, 0, 1]) = }')\n",
    "print(f'{predict_for_sequence([1, 0, 0, 0, 0, 1, 0, 1]) = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115002f7-416c-478c-9280-7ecd19d7e6dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
