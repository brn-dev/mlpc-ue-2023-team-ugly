{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torch import nn\n",
    "\n",
    "from lib.data_preprocessing import remove_correlated_columns, normalize_data\n",
    "from lib.ds.bird_classes import NUM_CLASSES\n",
    "from lib.ds.dataset_loading import load_all_data\n",
    "from lib.ds.dataset_splitting import split\n",
    "from lib.ds.torch_dataset import create_data_loader\n",
    "from lib.model.attention_classifier import AttentionClassifier, AttentionClassifierHyperParameters\n",
    "from lib.attention_classifier_training import train_attention_classifier_with_cv, train_attention_classifier, test_attention_classifier\n",
    "from lib.training_hyper_parameters import TrainingHyperParameters\n",
    "from lib.ds.numpy_dataset import NumpyDataset\n",
    "from lib.model.model_persistence import save_model, load_model\n",
    "from lib.random import set_random_seed\n",
    "import lib.torch_device as tdev\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tdev.PREFERRED = 'cpu'\n",
    "device = tdev.get_torch_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, labels_train, data_test, labels_test = split(*load_all_data('dataset'), seed=69421)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlated_columns_to_drop = array([  0,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "        28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,\n",
      "        41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,\n",
      "        54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,\n",
      "        67,  68,  69,  70,  71,  72,  73,  74,  78,  79,  80,  81,  82,\n",
      "        83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,\n",
      "        96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108,\n",
      "       109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121,\n",
      "       122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 133, 134, 156,\n",
      "       157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "       170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,\n",
      "       183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "       196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
      "       209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221,\n",
      "       222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234,\n",
      "       235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "       248, 249, 250, 251, 252, 253, 254, 255, 292, 293, 294, 295, 296,\n",
      "       297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309,\n",
      "       310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322,\n",
      "       323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 335, 336,\n",
      "       338, 339, 340, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "       392, 393, 399, 400, 462, 463, 526, 527, 528, 529, 530])\n"
     ]
    }
   ],
   "source": [
    "data_train, data_test = remove_correlated_columns(data_train, data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(960, 100, 264)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 100, 264)\n",
      "(60, 100)\n"
     ]
    }
   ],
   "source": [
    "set_random_seed(42)\n",
    "subset_indices = [\n",
    "    bird * data_train.shape[0] // 6 + sample_nr\n",
    "    for bird in range(6)\n",
    "    for sample_nr in range(10)\n",
    "]\n",
    "# data_train_subset = data_train[subset_indices, :, :]\n",
    "# labels_train_subset = labels_train[subset_indices, :]\n",
    "data_train_subset = data_train[subset_indices, :, :]\n",
    "labels_train_subset = labels_train[subset_indices, :]\n",
    "print(data_train_subset.shape)\n",
    "print(labels_train_subset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_parameters = AttentionClassifierHyperParameters(\n",
    "    in_features=data_train.shape[-1],\n",
    "    out_features=NUM_CLASSES,\n",
    "    d_model=64,\n",
    "    num_heads=8,\n",
    "    stack_size=1,\n",
    "    dropout=0.1,\n",
    "    in_linear_hidden_out_features=[128],\n",
    "    out_linear_hidden_out_features=[128],\n",
    "    linear_activation_provider=lambda: nn.LeakyReLU(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH_MULTIPLIER = 1\n",
    "\n",
    "training_hyper_parameters = TrainingHyperParameters(\n",
    "    batch_size=32,\n",
    "    num_epochs=int(150 * EPOCH_MULTIPLIER),\n",
    "    lr=5e-3,\n",
    "    lr_scheduler_provider=lambda optimizer: lr_scheduler.MultiStepLR(\n",
    "        optimizer, \n",
    "        milestones=[int(m * EPOCH_MULTIPLIER) for m in [20, 60, 100]],  # [10, 30, 60, 100]], \n",
    "        gamma=0.5\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 0\n",
      "Training AttentionClassifier with 68039 parameters\n",
      "loss_weight = tensor([ 1.0000, 15.8275,  9.6494, 10.6295, 36.9184, 17.7606, 19.8364],\n",
      "       device='cuda:0')\n",
      "Training Epoch 0  : lr = 0.005000, epoch_loss = 42.202817, num_correct = 13104, num_samples = 85536, acc = 0.153199, bacc = 0.332055\n",
      "Evaluated with loss = 0.043911, acc = 0.328598, bacc = 0.583867\n",
      "Training Epoch 1  : lr = 0.005000, epoch_loss = 23.993338, num_correct = 22511, num_samples = 85536, acc = 0.263176, bacc = 0.490375\n",
      "Evaluated with loss = 0.004087, acc = 0.306082, bacc = 0.759157\n",
      "Training Epoch 2  : lr = 0.005000, epoch_loss = 17.221240, num_correct = 25007, num_samples = 85536, acc = 0.292356, bacc = 0.583637\n",
      "Evaluated with loss = 0.005539, acc = 0.319655, bacc = 0.750041\n",
      "Training Epoch 3  : lr = 0.005000, epoch_loss = 14.737989, num_correct = 25822, num_samples = 85536, acc = 0.301885, bacc = 0.643599\n",
      "Evaluated with loss = 0.003549, acc = 0.345644, bacc = 0.778425\n",
      "Training Epoch 4  : lr = 0.005000, epoch_loss = 14.231354, num_correct = 26803, num_samples = 85536, acc = 0.313353, bacc = 0.678906\n",
      "Evaluated with loss = 0.004405, acc = 0.320602, bacc = 0.796837\n",
      "Training Epoch 5  : lr = 0.005000, epoch_loss = 13.454189, num_correct = 26236, num_samples = 85536, acc = 0.306725, bacc = 0.703629\n",
      "Evaluated with loss = 0.006320, acc = 0.300505, bacc = 0.699812\n",
      "Training Epoch 6  : lr = 0.005000, epoch_loss = 13.276656, num_correct = 25897, num_samples = 85536, acc = 0.302761, bacc = 0.721520\n",
      "Evaluated with loss = 0.003412, acc = 0.302083, bacc = 0.716102\n",
      "Training Epoch 7  : lr = 0.005000, epoch_loss = 13.253196, num_correct = 25801, num_samples = 85536, acc = 0.301639, bacc = 0.735168\n",
      "Evaluated with loss = 0.004913, acc = 0.319129, bacc = 0.781891\n",
      "Training Epoch 8  : lr = 0.005000, epoch_loss = 11.296777, num_correct = 26489, num_samples = 85536, acc = 0.309682, bacc = 0.748199\n",
      "Evaluated with loss = 0.004193, acc = 0.336911, bacc = 0.786656\n",
      "Training Epoch 9  : lr = 0.005000, epoch_loss = 11.271841, num_correct = 26506, num_samples = 85536, acc = 0.309881, bacc = 0.758709\n",
      "Evaluated with loss = 0.000379, acc = 0.363005, bacc = 0.810671\n",
      "Training Epoch 10 : lr = 0.005000, epoch_loss = 11.902025, num_correct = 26989, num_samples = 85536, acc = 0.315528, bacc = 0.766875\n",
      "Evaluated with loss = 0.000465, acc = 0.352799, bacc = 0.796859\n",
      "Training Epoch 11 : lr = 0.005000, epoch_loss = 10.951395, num_correct = 27755, num_samples = 85536, acc = 0.324483, bacc = 0.774141\n",
      "Evaluated with loss = 0.000425, acc = 0.346486, bacc = 0.811924\n",
      "Training Epoch 12 : lr = 0.005000, epoch_loss = 10.627577, num_correct = 27412, num_samples = 85536, acc = 0.320473, bacc = 0.780444\n",
      "Evaluated with loss = 0.000413, acc = 0.354482, bacc = 0.808650\n",
      "Training Epoch 13 : lr = 0.005000, epoch_loss = 10.586743, num_correct = 27598, num_samples = 85536, acc = 0.322648, bacc = 0.786003\n",
      "Evaluated with loss = 0.000400, acc = 0.376999, bacc = 0.793474\n",
      "Training Epoch 14 : lr = 0.005000, epoch_loss = 10.467861, num_correct = 27810, num_samples = 85536, acc = 0.325126, bacc = 0.790764\n",
      "Evaluated with loss = 0.000431, acc = 0.365109, bacc = 0.765182\n",
      "Training Epoch 15 : lr = 0.005000, epoch_loss = 10.538229, num_correct = 27689, num_samples = 85536, acc = 0.323712, bacc = 0.794983\n",
      "Evaluated with loss = 0.000417, acc = 0.353746, bacc = 0.773942\n",
      "Training Epoch 16 : lr = 0.005000, epoch_loss = 10.420677, num_correct = 28513, num_samples = 85536, acc = 0.333345, bacc = 0.798727\n",
      "Evaluated with loss = 0.000398, acc = 0.371317, bacc = 0.774201\n",
      "Training Epoch 17 : lr = 0.005000, epoch_loss = 10.416411, num_correct = 28555, num_samples = 85536, acc = 0.333836, bacc = 0.802155\n",
      "Evaluated with loss = 0.000418, acc = 0.331334, bacc = 0.756058\n",
      "Training Epoch 18 : lr = 0.005000, epoch_loss = 10.527651, num_correct = 27484, num_samples = 85536, acc = 0.321315, bacc = 0.805121\n",
      "Evaluated with loss = 0.000392, acc = 0.392045, bacc = 0.766403\n",
      "Training Epoch 19 : lr = 0.005000, epoch_loss = 10.774471, num_correct = 27847, num_samples = 85536, acc = 0.325559, bacc = 0.807764\n",
      "Evaluated with loss = 0.000399, acc = 0.345013, bacc = 0.793438\n",
      "Training Epoch 20 : lr = 0.002500, epoch_loss = 10.523843, num_correct = 27716, num_samples = 85536, acc = 0.324027, bacc = 0.810106\n",
      "Evaluated with loss = 0.000408, acc = 0.339962, bacc = 0.811277\n",
      "Training Epoch 21 : lr = 0.002500, epoch_loss = 10.201617, num_correct = 28744, num_samples = 85536, acc = 0.336046, bacc = 0.812448\n",
      "Evaluated with loss = 0.000374, acc = 0.355219, bacc = 0.789985\n",
      "Training Epoch 22 : lr = 0.002500, epoch_loss = 10.108893, num_correct = 28661, num_samples = 85536, acc = 0.335075, bacc = 0.814642\n",
      "Evaluated with loss = 0.000365, acc = 0.375737, bacc = 0.786245\n",
      "Training Epoch 23 : lr = 0.002500, epoch_loss = 10.071050, num_correct = 28934, num_samples = 85536, acc = 0.338267, bacc = 0.816644\n",
      "Evaluated with loss = 0.000387, acc = 0.360795, bacc = 0.791159\n",
      "Training Epoch 24 : lr = 0.002500, epoch_loss = 9.979581, num_correct = 29183, num_samples = 85536, acc = 0.341178, bacc = 0.818484\n",
      "Evaluated with loss = 0.000387, acc = 0.364583, bacc = 0.789882\n",
      "Training Epoch 25 : lr = 0.002500, epoch_loss = 9.979639, num_correct = 29053, num_samples = 85536, acc = 0.339658, bacc = 0.820220\n",
      "Evaluated with loss = 0.000385, acc = 0.363847, bacc = 0.800656\n",
      "Training Epoch 26 : lr = 0.002500, epoch_loss = 9.972985, num_correct = 29009, num_samples = 85536, acc = 0.339144, bacc = 0.821802\n",
      "Evaluated with loss = 0.000393, acc = 0.367635, bacc = 0.785526\n",
      "Training Epoch 27 : lr = 0.002500, epoch_loss = 9.992926, num_correct = 29312, num_samples = 85536, acc = 0.342686, bacc = 0.823269\n",
      "Evaluated with loss = 0.000392, acc = 0.367529, bacc = 0.788506\n",
      "Training Epoch 28 : lr = 0.002500, epoch_loss = 10.122538, num_correct = 29521, num_samples = 85536, acc = 0.345130, bacc = 0.824584\n",
      "Evaluated with loss = 0.000381, acc = 0.391098, bacc = 0.792992\n",
      "Training Epoch 29 : lr = 0.002500, epoch_loss = 10.051208, num_correct = 28946, num_samples = 85536, acc = 0.338407, bacc = 0.825848\n",
      "Evaluated with loss = 0.000397, acc = 0.347748, bacc = 0.799765\n",
      "Training Epoch 30 : lr = 0.002500, epoch_loss = 9.970387, num_correct = 29063, num_samples = 85536, acc = 0.339775, bacc = 0.827063\n",
      "Evaluated with loss = 0.000396, acc = 0.325968, bacc = 0.809006\n",
      "Training Epoch 31 : lr = 0.002500, epoch_loss = 9.901482, num_correct = 29277, num_samples = 85536, acc = 0.342277, bacc = 0.828209\n",
      "Evaluated with loss = 0.000425, acc = 0.334491, bacc = 0.806408\n",
      "Training Epoch 32 : lr = 0.002500, epoch_loss = 9.919637, num_correct = 29255, num_samples = 85536, acc = 0.342020, bacc = 0.829282\n",
      "Evaluated with loss = 0.000392, acc = 0.369529, bacc = 0.798109\n",
      "Training Epoch 33 : lr = 0.002500, epoch_loss = 10.018733, num_correct = 29699, num_samples = 85536, acc = 0.347211, bacc = 0.830227\n",
      "Evaluated with loss = 0.000382, acc = 0.348590, bacc = 0.784248\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [67]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m set_random_seed(\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m cv_models \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_attention_classifier_with_cv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhyper_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_hyper_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mNumpyDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Dropbox\\jku\\2023SS\\344.091 - Machine Learning and Pattern Classification\\lib\\attention_classifier_training.py:47\u001b[0m, in \u001b[0;36mtrain_attention_classifier_with_cv\u001b[1;34m(hyper_parameters, training_hyper_parameters, dataset, device)\u001b[0m\n\u001b[0;32m     44\u001b[0m     save_model(model, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_classifier fold-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_nr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     45\u001b[0m     models\u001b[38;5;241m.\u001b[39mappend(model)\n\u001b[1;32m---> 47\u001b[0m \u001b[43mtrain_with_cv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m models\n",
      "File \u001b[1;32m~\\Dropbox\\jku\\2023SS\\344.091 - Machine Learning and Pattern Classification\\lib\\training.py:30\u001b[0m, in \u001b[0;36mtrain_with_cv\u001b[1;34m(dataset, train_func, n_folds)\u001b[0m\n\u001b[0;32m     25\u001b[0m labels_train \u001b[38;5;241m=\u001b[39m labels_folds[np\u001b[38;5;241m.\u001b[39msetdiff1d(\u001b[38;5;28mrange\u001b[39m(n_folds), fold)] \\\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, labels_folds\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m     28\u001b[0m data_train_normalized, data_validation_normalized \u001b[38;5;241m=\u001b[39m normalize_data(data_train, data_validation)\n\u001b[1;32m---> 30\u001b[0m \u001b[43mtrain_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mNumpyDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_train_normalized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mNumpyDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_validation_normalized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_validation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Dropbox\\jku\\2023SS\\344.091 - Machine Learning and Pattern Classification\\lib\\attention_classifier_training.py:32\u001b[0m, in \u001b[0;36mtrain_attention_classifier_with_cv.<locals>.train_func\u001b[1;34m(fold_nr, train_ds, eval_ds)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_func\u001b[39m(fold_nr: \u001b[38;5;28mint\u001b[39m, train_ds: NumpyDataset, eval_ds: NumpyDataset):\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_nr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 32\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_attention_classifier\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhyper_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining_hyper_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvaluating fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_nr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     41\u001b[0m     eval_data_loader \u001b[38;5;241m=\u001b[39m create_data_loader(eval_ds\u001b[38;5;241m.\u001b[39mdata, eval_ds\u001b[38;5;241m.\u001b[39mlabels, training_hyper_parameters\u001b[38;5;241m.\u001b[39mbatch_size)\n",
      "File \u001b[1;32m~\\Dropbox\\jku\\2023SS\\344.091 - Machine Learning and Pattern Classification\\lib\\attention_classifier_training.py:80\u001b[0m, in \u001b[0;36mtrain_attention_classifier\u001b[1;34m(hyper_parameters, training_hyper_parameters, train_ds, eval_ds, device)\u001b[0m\n\u001b[0;32m     77\u001b[0m loss_weight \u001b[38;5;241m=\u001b[39m calculate_loss_weight(train_ds\u001b[38;5;241m.\u001b[39mlabels)\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_weight \u001b[38;5;132;01m= }\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 80\u001b[0m \u001b[43m_train_attention_classifier\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_classifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_data_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_hyper_parameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m attention_classifier\n",
      "File \u001b[1;32m~\\Dropbox\\jku\\2023SS\\344.091 - Machine Learning and Pattern Classification\\lib\\attention_classifier_training.py:137\u001b[0m, in \u001b[0;36m_train_attention_classifier\u001b[1;34m(model, train_data_loader, eval_data_loader, optimizer, loss_weight, num_epochs, lr_scheduler, device)\u001b[0m\n\u001b[0;32m    134\u001b[0m     all_target_labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((all_target_labels, labels\u001b[38;5;241m.\u001b[39mcpu()))\n\u001b[0;32m    136\u001b[0m acc \u001b[38;5;241m=\u001b[39m num_correct \u001b[38;5;241m/\u001b[39m num_samples\n\u001b[1;32m--> 137\u001b[0m bacc \u001b[38;5;241m=\u001b[39m \u001b[43msklearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbalanced_accuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_target_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_pred_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<3\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mget_lr(optimizer)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbacc \u001b[38;5;132;01m= :\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    146\u001b[0m )\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lr_scheduler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2180\u001b[0m, in \u001b[0;36mbalanced_accuracy_score\u001b[1;34m(y_true, y_pred, sample_weight, adjusted)\u001b[0m\n\u001b[0;32m   2111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbalanced_accuracy_score\u001b[39m(y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, adjusted\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   2112\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute the balanced accuracy.\u001b[39;00m\n\u001b[0;32m   2113\u001b[0m \n\u001b[0;32m   2114\u001b[0m \u001b[38;5;124;03m    The balanced accuracy in binary and multiclass classification problems to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2178\u001b[0m \u001b[38;5;124;03m    0.625\u001b[39;00m\n\u001b[0;32m   2179\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2180\u001b[0m     C \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2181\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(divide\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   2182\u001b[0m         per_class \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdiag(C) \u001b[38;5;241m/\u001b[39m C\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:317\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconfusion_matrix\u001b[39m(\n\u001b[0;32m    233\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    234\u001b[0m ):\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \n\u001b[0;32m    237\u001b[0m \u001b[38;5;124;03m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;124;03m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 317\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "File \u001b[1;32mc:\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:87\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \n\u001b[0;32m     62\u001b[0m \u001b[38;5;124;03mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;124;03my_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     86\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[1;32m---> 87\u001b[0m type_true \u001b[38;5;241m=\u001b[39m \u001b[43mtype_of_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my_true\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     90\u001b[0m y_type \u001b[38;5;241m=\u001b[39m {type_true, type_pred}\n",
      "File \u001b[1;32mc:\\python39\\lib\\site-packages\\sklearn\\utils\\multiclass.py:386\u001b[0m, in \u001b[0;36mtype_of_target\u001b[1;34m(y, input_name)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;66;03m# Check multiclass\u001b[39;00m\n\u001b[0;32m    385\u001b[0m first_row \u001b[38;5;241m=\u001b[39m y[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m issparse(y) \u001b[38;5;28;01melse\u001b[39;00m y\u001b[38;5;241m.\u001b[39mgetrow(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m--> 386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(first_row) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    387\u001b[0m     \u001b[38;5;66;03m# [1, 2, 3] or [[1., 2., 3]] or [[1, 2]]\u001b[39;00m\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m suffix\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\python39\\lib\\site-packages\\sklearn\\utils\\_array_api.py:84\u001b[0m, in \u001b[0;36m_NumPyApiWrapper.unique_values\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munique_values\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36munique\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\python39\\lib\\site-packages\\numpy\\lib\\arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[0;32m    272\u001b[0m ar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(ar)\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 274\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43m_unique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mequal_nan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[0;32m    278\u001b[0m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[1;32mc:\\python39\\lib\\site-packages\\numpy\\lib\\arraysetops.py:336\u001b[0m, in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[0;32m    334\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar[perm]\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 336\u001b[0m     \u001b[43mar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    337\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar\n\u001b[0;32m    338\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(aux\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mbool_)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "set_random_seed(42)\n",
    "\n",
    "cv_models = train_attention_classifier_with_cv(\n",
    "    hyper_parameters, \n",
    "    training_hyper_parameters, \n",
    "    NumpyDataset(data_train, labels_train),\n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AttentionClassifier with 68039 parameters\n",
      "loss_weight = tensor([ 1.0000, 15.3204,  9.3547, 10.4259, 36.4963, 17.9374, 19.6462],\n",
      "       device='cuda:0')\n",
      "Training Epoch 0  : lr = 0.005000, epoch_loss = 61.057405, num_correct = 17172, num_samples = 95040, acc = 0.180682, bacc = 0.227976\n",
      "Training Epoch 1  : lr = 0.005000, epoch_loss = 76.761902, num_correct =  2565, num_samples = 95040, acc = 0.026989, bacc = 0.150810\n",
      "Training Epoch 2  : lr = 0.005000, epoch_loss = 70.233804, num_correct =  3614, num_samples = 95040, acc = 0.038026, bacc = 0.130356\n",
      "Training Epoch 3  : lr = 0.005000, epoch_loss = 70.193547, num_correct =  5435, num_samples = 95040, acc = 0.057186, bacc = 0.145486\n",
      "Training Epoch 4  : lr = 0.005000, epoch_loss = 70.291492, num_correct = 28746, num_samples = 95040, acc = 0.302462, bacc = 0.155497\n",
      "Training Epoch 5  : lr = 0.005000, epoch_loss = 83.554285, num_correct =  1091, num_samples = 95040, acc = 0.011479, bacc = 0.129964\n",
      "Training Epoch 6  : lr = 0.005000, epoch_loss = 63.584809, num_correct =  1961, num_samples = 95040, acc = 0.020633, bacc = 0.119590\n",
      "Training Epoch 7  : lr = 0.005000, epoch_loss = 49.805556, num_correct =  8217, num_samples = 95040, acc = 0.086458, bacc = 0.139171\n",
      "Training Epoch 8  : lr = 0.005000, epoch_loss = 58.949348, num_correct =  9881, num_samples = 95040, acc = 0.103967, bacc = 0.149261\n",
      "Training Epoch 9  : lr = 0.005000, epoch_loss = 48.499921, num_correct =  9572, num_samples = 95040, acc = 0.100715, bacc = 0.165883\n",
      "Training Epoch 10 : lr = 0.005000, epoch_loss = 40.249839, num_correct = 15326, num_samples = 95040, acc = 0.161258, bacc = 0.189827\n",
      "Training Epoch 11 : lr = 0.005000, epoch_loss = 51.694895, num_correct = 23931, num_samples = 95040, acc = 0.251799, bacc = 0.196703\n",
      "Training Epoch 12 : lr = 0.005000, epoch_loss = 63.085287, num_correct = 16150, num_samples = 95040, acc = 0.169928, bacc = 0.199751\n",
      "Training Epoch 13 : lr = 0.005000, epoch_loss = 52.365914, num_correct = 15180, num_samples = 95040, acc = 0.159722, bacc = 0.205790\n",
      "Training Epoch 14 : lr = 0.005000, epoch_loss = 38.995003, num_correct = 14177, num_samples = 95040, acc = 0.149169, bacc = 0.222121\n",
      "Training Epoch 15 : lr = 0.005000, epoch_loss = 41.662700, num_correct = 18719, num_samples = 95040, acc = 0.196959, bacc = 0.231463\n",
      "Training Epoch 16 : lr = 0.005000, epoch_loss = 30.937120, num_correct = 19565, num_samples = 95040, acc = 0.205861, bacc = 0.250953\n",
      "Training Epoch 17 : lr = 0.005000, epoch_loss = 44.535495, num_correct = 26336, num_samples = 95040, acc = 0.277104, bacc = 0.268028\n",
      "Training Epoch 18 : lr = 0.005000, epoch_loss = 33.345017, num_correct = 22698, num_samples = 95040, acc = 0.238826, bacc = 0.283592\n",
      "Training Epoch 19 : lr = 0.005000, epoch_loss = 28.856955, num_correct = 19560, num_samples = 95040, acc = 0.205808, bacc = 0.302378\n",
      "Training Epoch 20 : lr = 0.002500, epoch_loss = 31.194959, num_correct = 23220, num_samples = 95040, acc = 0.244318, bacc = 0.314508\n",
      "Training Epoch 21 : lr = 0.002500, epoch_loss = 22.759527, num_correct = 24426, num_samples = 95040, acc = 0.257008, bacc = 0.333237\n",
      "Training Epoch 22 : lr = 0.002500, epoch_loss = 22.934308, num_correct = 26462, num_samples = 95040, acc = 0.278430, bacc = 0.350443\n",
      "Training Epoch 23 : lr = 0.002500, epoch_loss = 22.846491, num_correct = 28731, num_samples = 95040, acc = 0.302304, bacc = 0.366106\n",
      "Training Epoch 24 : lr = 0.002500, epoch_loss = 21.008811, num_correct = 26481, num_samples = 95040, acc = 0.278630, bacc = 0.381496\n",
      "Training Epoch 25 : lr = 0.002500, epoch_loss = 23.321582, num_correct = 27764, num_samples = 95040, acc = 0.292130, bacc = 0.393543\n",
      "Training Epoch 26 : lr = 0.002500, epoch_loss = 21.363462, num_correct = 25941, num_samples = 95040, acc = 0.272948, bacc = 0.406303\n",
      "Training Epoch 27 : lr = 0.002500, epoch_loss = 22.600992, num_correct = 23023, num_samples = 95040, acc = 0.242245, bacc = 0.417945\n",
      "Training Epoch 28 : lr = 0.002500, epoch_loss = 21.108076, num_correct = 28295, num_samples = 95040, acc = 0.297717, bacc = 0.429665\n",
      "Training Epoch 29 : lr = 0.002500, epoch_loss = 18.706681, num_correct = 26345, num_samples = 95040, acc = 0.277199, bacc = 0.442061\n",
      "Training Epoch 30 : lr = 0.002500, epoch_loss = 18.549780, num_correct = 29236, num_samples = 95040, acc = 0.307618, bacc = 0.453127\n",
      "Training Epoch 31 : lr = 0.002500, epoch_loss = 16.543324, num_correct = 28392, num_samples = 95040, acc = 0.298737, bacc = 0.464775\n",
      "Training Epoch 32 : lr = 0.002500, epoch_loss = 19.141751, num_correct = 34993, num_samples = 95040, acc = 0.368192, bacc = 0.474125\n",
      "Training Epoch 33 : lr = 0.002500, epoch_loss = 16.986298, num_correct = 29990, num_samples = 95040, acc = 0.315551, bacc = 0.484330\n",
      "Training Epoch 34 : lr = 0.002500, epoch_loss = 18.919852, num_correct = 33543, num_samples = 95040, acc = 0.352936, bacc = 0.492559\n",
      "Training Epoch 35 : lr = 0.002500, epoch_loss = 15.723958, num_correct = 30772, num_samples = 95040, acc = 0.323779, bacc = 0.501453\n",
      "Training Epoch 36 : lr = 0.002500, epoch_loss = 14.152939, num_correct = 28537, num_samples = 95040, acc = 0.300263, bacc = 0.510938\n",
      "Training Epoch 37 : lr = 0.002500, epoch_loss = 15.286378, num_correct = 31679, num_samples = 95040, acc = 0.333323, bacc = 0.519407\n",
      "Training Epoch 38 : lr = 0.002500, epoch_loss = 14.991767, num_correct = 29635, num_samples = 95040, acc = 0.311816, bacc = 0.527617\n",
      "Training Epoch 39 : lr = 0.002500, epoch_loss = 17.867094, num_correct = 36389, num_samples = 95040, acc = 0.382881, bacc = 0.532607\n",
      "Training Epoch 40 : lr = 0.002500, epoch_loss = 22.672600, num_correct = 25499, num_samples = 95040, acc = 0.268298, bacc = 0.537855\n",
      "Training Epoch 41 : lr = 0.002500, epoch_loss = 19.488102, num_correct = 28528, num_samples = 95040, acc = 0.300168, bacc = 0.543584\n",
      "Training Epoch 42 : lr = 0.002500, epoch_loss = 16.340403, num_correct = 27266, num_samples = 95040, acc = 0.286890, bacc = 0.549750\n",
      "Training Epoch 43 : lr = 0.002500, epoch_loss = 16.656152, num_correct = 29387, num_samples = 95040, acc = 0.309207, bacc = 0.555791\n",
      "Training Epoch 44 : lr = 0.002500, epoch_loss = 12.766512, num_correct = 30428, num_samples = 95040, acc = 0.320160, bacc = 0.562476\n",
      "Training Epoch 45 : lr = 0.002500, epoch_loss = 13.124196, num_correct = 31777, num_samples = 95040, acc = 0.334354, bacc = 0.568827\n",
      "Training Epoch 46 : lr = 0.002500, epoch_loss = 14.622346, num_correct = 32540, num_samples = 95040, acc = 0.342382, bacc = 0.574198\n",
      "Training Epoch 47 : lr = 0.002500, epoch_loss = 15.279837, num_correct = 35682, num_samples = 95040, acc = 0.375442, bacc = 0.579238\n",
      "Training Epoch 48 : lr = 0.002500, epoch_loss = 13.718116, num_correct = 28891, num_samples = 95040, acc = 0.303988, bacc = 0.584796\n",
      "Training Epoch 49 : lr = 0.002500, epoch_loss = 14.420986, num_correct = 33237, num_samples = 95040, acc = 0.349716, bacc = 0.589737\n",
      "Training Epoch 50 : lr = 0.002500, epoch_loss = 13.466247, num_correct = 29150, num_samples = 95040, acc = 0.306713, bacc = 0.594847\n",
      "Training Epoch 51 : lr = 0.002500, epoch_loss = 15.634035, num_correct = 33133, num_samples = 95040, acc = 0.348622, bacc = 0.598974\n",
      "Training Epoch 52 : lr = 0.002500, epoch_loss = 15.193666, num_correct = 29230, num_samples = 95040, acc = 0.307555, bacc = 0.603261\n",
      "Training Epoch 53 : lr = 0.002500, epoch_loss = 13.693361, num_correct = 29988, num_samples = 95040, acc = 0.315530, bacc = 0.607800\n",
      "Training Epoch 54 : lr = 0.002500, epoch_loss = 14.307059, num_correct = 32523, num_samples = 95040, acc = 0.342203, bacc = 0.612094\n",
      "Training Epoch 55 : lr = 0.002500, epoch_loss = 13.510802, num_correct = 31345, num_samples = 95040, acc = 0.329809, bacc = 0.616393\n",
      "Training Epoch 56 : lr = 0.002500, epoch_loss = 14.304537, num_correct = 32104, num_samples = 95040, acc = 0.337795, bacc = 0.620327\n",
      "Training Epoch 57 : lr = 0.002500, epoch_loss = 14.549361, num_correct = 30535, num_samples = 95040, acc = 0.321286, bacc = 0.624023\n",
      "Training Epoch 58 : lr = 0.002500, epoch_loss = 17.081786, num_correct = 34643, num_samples = 95040, acc = 0.364510, bacc = 0.626416\n",
      "Training Epoch 59 : lr = 0.002500, epoch_loss = 12.691221, num_correct = 29684, num_samples = 95040, acc = 0.312332, bacc = 0.630275\n",
      "Training Epoch 60 : lr = 0.001250, epoch_loss = 13.397707, num_correct = 33639, num_samples = 95040, acc = 0.353946, bacc = 0.633785\n",
      "Training Epoch 61 : lr = 0.001250, epoch_loss = 12.259690, num_correct = 29539, num_samples = 95040, acc = 0.310806, bacc = 0.637437\n",
      "Training Epoch 62 : lr = 0.001250, epoch_loss = 11.791286, num_correct = 30481, num_samples = 95040, acc = 0.320718, bacc = 0.640998\n",
      "Training Epoch 63 : lr = 0.001250, epoch_loss = 11.896083, num_correct = 32246, num_samples = 95040, acc = 0.339289, bacc = 0.644415\n",
      "Training Epoch 64 : lr = 0.001250, epoch_loss = 12.160960, num_correct = 30922, num_samples = 95040, acc = 0.325358, bacc = 0.647742\n",
      "Training Epoch 65 : lr = 0.001250, epoch_loss = 12.054014, num_correct = 32066, num_samples = 95040, acc = 0.337395, bacc = 0.650946\n",
      "Training Epoch 66 : lr = 0.001250, epoch_loss = 12.182727, num_correct = 31992, num_samples = 95040, acc = 0.336616, bacc = 0.654089\n",
      "Training Epoch 67 : lr = 0.001250, epoch_loss = 11.903711, num_correct = 32810, num_samples = 95040, acc = 0.345223, bacc = 0.657116\n",
      "Training Epoch 68 : lr = 0.001250, epoch_loss = 12.431626, num_correct = 32721, num_samples = 95040, acc = 0.344287, bacc = 0.660040\n",
      "Training Epoch 69 : lr = 0.001250, epoch_loss = 11.906498, num_correct = 33786, num_samples = 95040, acc = 0.355492, bacc = 0.662871\n",
      "Training Epoch 70 : lr = 0.001250, epoch_loss = 12.046249, num_correct = 30658, num_samples = 95040, acc = 0.322580, bacc = 0.665649\n",
      "Training Epoch 71 : lr = 0.001250, epoch_loss = 11.722562, num_correct = 33709, num_samples = 95040, acc = 0.354682, bacc = 0.668341\n",
      "Training Epoch 72 : lr = 0.001250, epoch_loss = 11.855320, num_correct = 31586, num_samples = 95040, acc = 0.332344, bacc = 0.671001\n",
      "Training Epoch 73 : lr = 0.001250, epoch_loss = 11.982071, num_correct = 34873, num_samples = 95040, acc = 0.366930, bacc = 0.673491\n",
      "Training Epoch 74 : lr = 0.001250, epoch_loss = 12.152079, num_correct = 31631, num_samples = 95040, acc = 0.332818, bacc = 0.675994\n",
      "Training Epoch 75 : lr = 0.001250, epoch_loss = 11.846338, num_correct = 33633, num_samples = 95040, acc = 0.353883, bacc = 0.678397\n",
      "Training Epoch 76 : lr = 0.001250, epoch_loss = 11.916002, num_correct = 33419, num_samples = 95040, acc = 0.351631, bacc = 0.680746\n",
      "Training Epoch 77 : lr = 0.001250, epoch_loss = 11.583676, num_correct = 32282, num_samples = 95040, acc = 0.339668, bacc = 0.683057\n",
      "Training Epoch 78 : lr = 0.001250, epoch_loss = 11.735013, num_correct = 32484, num_samples = 95040, acc = 0.341793, bacc = 0.685316\n",
      "Training Epoch 79 : lr = 0.001250, epoch_loss = 11.722542, num_correct = 31781, num_samples = 95040, acc = 0.334396, bacc = 0.687516\n",
      "Training Epoch 80 : lr = 0.001250, epoch_loss = 12.303886, num_correct = 35497, num_samples = 95040, acc = 0.373495, bacc = 0.689612\n",
      "Training Epoch 81 : lr = 0.001250, epoch_loss = 11.816946, num_correct = 31834, num_samples = 95040, acc = 0.334954, bacc = 0.691699\n",
      "Training Epoch 82 : lr = 0.001250, epoch_loss = 11.711139, num_correct = 33228, num_samples = 95040, acc = 0.349621, bacc = 0.693750\n",
      "Training Epoch 83 : lr = 0.001250, epoch_loss = 11.591432, num_correct = 31806, num_samples = 95040, acc = 0.334659, bacc = 0.695755\n",
      "Training Epoch 84 : lr = 0.001250, epoch_loss = 12.302924, num_correct = 36516, num_samples = 95040, acc = 0.384217, bacc = 0.697624\n",
      "Training Epoch 85 : lr = 0.001250, epoch_loss = 11.676237, num_correct = 31871, num_samples = 95040, acc = 0.335343, bacc = 0.699514\n",
      "Training Epoch 86 : lr = 0.001250, epoch_loss = 11.600471, num_correct = 33384, num_samples = 95040, acc = 0.351263, bacc = 0.701382\n",
      "Training Epoch 87 : lr = 0.001250, epoch_loss = 11.720419, num_correct = 31585, num_samples = 95040, acc = 0.332334, bacc = 0.703211\n",
      "Training Epoch 88 : lr = 0.001250, epoch_loss = 12.180304, num_correct = 36754, num_samples = 95040, acc = 0.386721, bacc = 0.704927\n",
      "Training Epoch 89 : lr = 0.001250, epoch_loss = 11.705651, num_correct = 31592, num_samples = 95040, acc = 0.332407, bacc = 0.706651\n",
      "Training Epoch 90 : lr = 0.001250, epoch_loss = 11.736219, num_correct = 34218, num_samples = 95040, acc = 0.360038, bacc = 0.708346\n",
      "Training Epoch 91 : lr = 0.001250, epoch_loss = 11.480171, num_correct = 31381, num_samples = 95040, acc = 0.330187, bacc = 0.710022\n",
      "Training Epoch 92 : lr = 0.001250, epoch_loss = 12.041950, num_correct = 36113, num_samples = 95040, acc = 0.379977, bacc = 0.711605\n",
      "Training Epoch 93 : lr = 0.001250, epoch_loss = 11.719611, num_correct = 31788, num_samples = 95040, acc = 0.334470, bacc = 0.713197\n",
      "Training Epoch 94 : lr = 0.001250, epoch_loss = 11.626771, num_correct = 33338, num_samples = 95040, acc = 0.350779, bacc = 0.714761\n",
      "Training Epoch 95 : lr = 0.001250, epoch_loss = 11.621663, num_correct = 32127, num_samples = 95040, acc = 0.338037, bacc = 0.716287\n",
      "Training Epoch 96 : lr = 0.001250, epoch_loss = 12.080083, num_correct = 35784, num_samples = 95040, acc = 0.376515, bacc = 0.717739\n",
      "Training Epoch 97 : lr = 0.001250, epoch_loss = 11.479765, num_correct = 31422, num_samples = 95040, acc = 0.330619, bacc = 0.719211\n",
      "Training Epoch 98 : lr = 0.001250, epoch_loss = 11.720473, num_correct = 34319, num_samples = 95040, acc = 0.361101, bacc = 0.720641\n",
      "Training Epoch 99 : lr = 0.001250, epoch_loss = 11.511379, num_correct = 31994, num_samples = 95040, acc = 0.336637, bacc = 0.722060\n",
      "Training Epoch 100: lr = 0.000625, epoch_loss = 11.477194, num_correct = 34005, num_samples = 95040, acc = 0.357797, bacc = 0.723437\n",
      "Training Epoch 101: lr = 0.000625, epoch_loss = 11.063514, num_correct = 31659, num_samples = 95040, acc = 0.333112, bacc = 0.724808\n",
      "Training Epoch 102: lr = 0.000625, epoch_loss = 11.011400, num_correct = 33222, num_samples = 95040, acc = 0.349558, bacc = 0.726156\n",
      "Training Epoch 103: lr = 0.000625, epoch_loss = 11.020397, num_correct = 32520, num_samples = 95040, acc = 0.342172, bacc = 0.727479\n",
      "Training Epoch 104: lr = 0.000625, epoch_loss = 11.169788, num_correct = 33717, num_samples = 95040, acc = 0.354766, bacc = 0.728774\n",
      "Training Epoch 105: lr = 0.000625, epoch_loss = 11.099949, num_correct = 32050, num_samples = 95040, acc = 0.337226, bacc = 0.730042\n",
      "Training Epoch 106: lr = 0.000625, epoch_loss = 11.096563, num_correct = 33348, num_samples = 95040, acc = 0.350884, bacc = 0.731285\n",
      "Training Epoch 107: lr = 0.000625, epoch_loss = 11.064943, num_correct = 32407, num_samples = 95040, acc = 0.340983, bacc = 0.732502\n",
      "Training Epoch 108: lr = 0.000625, epoch_loss = 11.138566, num_correct = 33718, num_samples = 95040, acc = 0.354777, bacc = 0.733702\n",
      "Training Epoch 109: lr = 0.000625, epoch_loss = 11.077660, num_correct = 32316, num_samples = 95040, acc = 0.340025, bacc = 0.734876\n",
      "Training Epoch 110: lr = 0.000625, epoch_loss = 11.098240, num_correct = 33587, num_samples = 95040, acc = 0.353399, bacc = 0.736034\n",
      "Training Epoch 111: lr = 0.000625, epoch_loss = 11.050573, num_correct = 32149, num_samples = 95040, acc = 0.338268, bacc = 0.737162\n",
      "Training Epoch 112: lr = 0.000625, epoch_loss = 11.131898, num_correct = 33816, num_samples = 95040, acc = 0.355808, bacc = 0.738277\n",
      "Training Epoch 113: lr = 0.000625, epoch_loss = 11.068772, num_correct = 32147, num_samples = 95040, acc = 0.338247, bacc = 0.739362\n",
      "Training Epoch 114: lr = 0.000625, epoch_loss = 11.102723, num_correct = 33552, num_samples = 95040, acc = 0.353030, bacc = 0.740442\n",
      "Training Epoch 115: lr = 0.000625, epoch_loss = 11.044302, num_correct = 32164, num_samples = 95040, acc = 0.338426, bacc = 0.741498\n",
      "Training Epoch 116: lr = 0.000625, epoch_loss = 11.096309, num_correct = 33704, num_samples = 95040, acc = 0.354630, bacc = 0.742538\n",
      "Training Epoch 117: lr = 0.000625, epoch_loss = 11.047168, num_correct = 31957, num_samples = 95040, acc = 0.336248, bacc = 0.743559\n",
      "Training Epoch 118: lr = 0.000625, epoch_loss = 11.087696, num_correct = 34071, num_samples = 95040, acc = 0.358491, bacc = 0.744568\n",
      "Training Epoch 119: lr = 0.000625, epoch_loss = 11.040204, num_correct = 31679, num_samples = 95040, acc = 0.333323, bacc = 0.745554\n",
      "Training Epoch 120: lr = 0.000625, epoch_loss = 11.078725, num_correct = 33944, num_samples = 95040, acc = 0.357155, bacc = 0.746527\n",
      "Training Epoch 121: lr = 0.000625, epoch_loss = 11.033553, num_correct = 32059, num_samples = 95040, acc = 0.337321, bacc = 0.747485\n",
      "Training Epoch 122: lr = 0.000625, epoch_loss = 11.082285, num_correct = 34228, num_samples = 95040, acc = 0.360143, bacc = 0.748427\n",
      "Training Epoch 123: lr = 0.000625, epoch_loss = 11.092221, num_correct = 31764, num_samples = 95040, acc = 0.334217, bacc = 0.749348\n",
      "Training Epoch 124: lr = 0.000625, epoch_loss = 11.074748, num_correct = 34050, num_samples = 95040, acc = 0.358270, bacc = 0.750259\n",
      "Training Epoch 125: lr = 0.000625, epoch_loss = 11.089580, num_correct = 31837, num_samples = 95040, acc = 0.334985, bacc = 0.751153\n",
      "Training Epoch 126: lr = 0.000625, epoch_loss = 11.093449, num_correct = 34195, num_samples = 95040, acc = 0.359796, bacc = 0.752034\n",
      "Training Epoch 127: lr = 0.000625, epoch_loss = 11.075711, num_correct = 31918, num_samples = 95040, acc = 0.335838, bacc = 0.752902\n",
      "Training Epoch 128: lr = 0.000625, epoch_loss = 11.061208, num_correct = 34207, num_samples = 95040, acc = 0.359922, bacc = 0.753755\n",
      "Training Epoch 129: lr = 0.000625, epoch_loss = 11.076341, num_correct = 32127, num_samples = 95040, acc = 0.338037, bacc = 0.754604\n",
      "Training Epoch 130: lr = 0.000625, epoch_loss = 11.062463, num_correct = 34306, num_samples = 95040, acc = 0.360964, bacc = 0.755438\n",
      "Training Epoch 131: lr = 0.000625, epoch_loss = 11.077881, num_correct = 32016, num_samples = 95040, acc = 0.336869, bacc = 0.756257\n",
      "Training Epoch 132: lr = 0.000625, epoch_loss = 11.053753, num_correct = 34052, num_samples = 95040, acc = 0.358291, bacc = 0.757059\n",
      "Training Epoch 133: lr = 0.000625, epoch_loss = 11.050475, num_correct = 32098, num_samples = 95040, acc = 0.337731, bacc = 0.757851\n",
      "Training Epoch 134: lr = 0.000625, epoch_loss = 11.060199, num_correct = 34210, num_samples = 95040, acc = 0.359954, bacc = 0.758631\n",
      "Training Epoch 135: lr = 0.000625, epoch_loss = 11.054954, num_correct = 31834, num_samples = 95040, acc = 0.334954, bacc = 0.759400\n",
      "Training Epoch 136: lr = 0.000625, epoch_loss = 11.054432, num_correct = 34127, num_samples = 95040, acc = 0.359080, bacc = 0.760158\n",
      "Training Epoch 137: lr = 0.000625, epoch_loss = 11.065673, num_correct = 32099, num_samples = 95040, acc = 0.337742, bacc = 0.760907\n",
      "Training Epoch 138: lr = 0.000625, epoch_loss = 11.052466, num_correct = 34217, num_samples = 95040, acc = 0.360027, bacc = 0.761642\n",
      "Training Epoch 139: lr = 0.000625, epoch_loss = 11.060382, num_correct = 31914, num_samples = 95040, acc = 0.335795, bacc = 0.762371\n",
      "Training Epoch 140: lr = 0.000625, epoch_loss = 11.034114, num_correct = 34270, num_samples = 95040, acc = 0.360585, bacc = 0.763088\n",
      "Training Epoch 141: lr = 0.000625, epoch_loss = 11.051063, num_correct = 32053, num_samples = 95040, acc = 0.337258, bacc = 0.763796\n",
      "Training Epoch 142: lr = 0.000625, epoch_loss = 11.043757, num_correct = 34166, num_samples = 95040, acc = 0.359491, bacc = 0.764491\n",
      "Training Epoch 143: lr = 0.000625, epoch_loss = 11.047235, num_correct = 32052, num_samples = 95040, acc = 0.337247, bacc = 0.765180\n",
      "Training Epoch 144: lr = 0.000625, epoch_loss = 11.023916, num_correct = 34260, num_samples = 95040, acc = 0.360480, bacc = 0.765857\n",
      "Training Epoch 145: lr = 0.000625, epoch_loss = 11.058739, num_correct = 31840, num_samples = 95040, acc = 0.335017, bacc = 0.766524\n",
      "Training Epoch 146: lr = 0.000625, epoch_loss = 11.052016, num_correct = 34178, num_samples = 95040, acc = 0.359617, bacc = 0.767185\n",
      "Training Epoch 147: lr = 0.000625, epoch_loss = 11.029893, num_correct = 32141, num_samples = 95040, acc = 0.338184, bacc = 0.767837\n",
      "Training Epoch 148: lr = 0.000625, epoch_loss = 11.034262, num_correct = 34182, num_samples = 95040, acc = 0.359659, bacc = 0.768477\n",
      "Training Epoch 149: lr = 0.000625, epoch_loss = 11.043974, num_correct = 31978, num_samples = 95040, acc = 0.336469, bacc = 0.769113\n",
      "Training finished\n",
      "Evaluated with loss = 0.000431, acc = 0.418981, bacc = 0.682321\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_random_seed(4354)\n",
    "\n",
    "data_train_normalized, data_test_normalized = normalize_data(data_train, data_test)\n",
    "\n",
    "attention_classifier = train_attention_classifier(\n",
    "    hyper_parameters, \n",
    "    training_hyper_parameters, \n",
    "    NumpyDataset(data_train_normalized, labels_train),\n",
    "    None,\n",
    "    device\n",
    ")\n",
    "\n",
    "# test_loader = create_data_loader(np.random.normal(size=(240, 100, 268)), np.random.randint(0, 7, size=(240, 100)))\n",
    "test_loader = create_data_loader(data_test_normalized, labels_test)\n",
    "test_attention_classifier(attention_classifier, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_test_normalized' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [35]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# load_model('attention_classifier fold-1')\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# TODO: normalization\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m create_data_loader(\u001b[43mdata_test_normalized\u001b[49m, labels_test)\n\u001b[0;32m      4\u001b[0m test_attention_classifier(load_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcv1/attention_classifier fold-0\u001b[39m\u001b[38;5;124m'\u001b[39m), test_loader, device)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_test_normalized' is not defined"
     ]
    }
   ],
   "source": [
    "# load_model('attention_classifier fold-1')\n",
    "# TODO: normalization\n",
    "test_loader = create_data_loader(data_test_normalized, labels_test)\n",
    "test_attention_classifier(load_model('cv1/attention_classifier fold-0'), test_loader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
